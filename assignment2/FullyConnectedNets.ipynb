{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Fully-Connected Neural Nets\n",
    "In the previous homework you implemented a fully-connected two-layer neural network on CIFAR-10. The implementation was simple but not very modular since the loss and gradient were computed in a single monolithic function. This is manageable for a simple two-layer network, but would become impractical as we move to bigger models. Ideally we want to build networks using a more modular design so that we can implement different layer types in isolation and then snap them together into models with different architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "In this exercise we will implement fully-connected networks using a more modular approach. For each layer we will implement a `forward` and a `backward` function. The `forward` function will receive inputs, weights, and other parameters and will return both an output and a `cache` object storing data needed for the backward pass, like this:\n",
    "\n",
    "```python\n",
    "def layer_forward(x, w):\n",
    "  \"\"\" Receive inputs x and weights w \"\"\"\n",
    "  # Do some computations ...\n",
    "  z = # ... some intermediate value\n",
    "  # Do some more computations ...\n",
    "  out = # the output\n",
    "   \n",
    "  cache = (x, w, z, out) # Values we need to compute gradients\n",
    "   \n",
    "  return out, cache\n",
    "```\n",
    "\n",
    "The backward pass will receive upstream derivatives and the `cache` object, and will return gradients with respect to the inputs and weights, like this:\n",
    "\n",
    "```python\n",
    "def layer_backward(dout, cache):\n",
    "  \"\"\"\n",
    "  Receive dout (derivative of loss with respect to outputs) and cache,\n",
    "  and compute derivative with respect to inputs.\n",
    "  \"\"\"\n",
    "  # Unpack cache values\n",
    "  x, w, z, out = cache\n",
    "  \n",
    "  # Use values in cache to compute derivatives\n",
    "  dx = # Derivative of loss with respect to x\n",
    "  dw = # Derivative of loss with respect to w\n",
    "  \n",
    "  return dx, dw\n",
    "```\n",
    "\n",
    "After implementing a bunch of layers this way, we will be able to easily combine them to build classifiers with different architectures.\n",
    "\n",
    "In addition to implementing fully-connected networks of arbitrary depth, we will also explore different update rules for optimization, and introduce Dropout as a regularizer and Batch/Layer Normalization as a tool to more efficiently optimize deep networks.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run the following from the cs231n directory and try again:\n",
      "python setup.py build_ext --inplace\n",
      "You may also need to restart your iPython kernel\n"
     ]
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.fc_net import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "# eval_numerical_gradient is used for the last layer (without upstream deritive \"dout\")\n",
    "# eval_numerical_gradient_array is used for hidden layer (with \"dout\")\n",
    "## eval_numerical_gradient can also be used for any hidden layer as long as model.loss function is used\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train: ', (49000, 3, 32, 32))\n",
      "('y_train: ', (49000,))\n",
      "('X_val: ', (1000, 3, 32, 32))\n",
      "('y_val: ', (1000,))\n",
      "('X_test: ', (1000, 3, 32, 32))\n",
      "('y_test: ', (1000,))\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "  print(('%s: ' % k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: foward\n",
    "Open the file `cs231n/layers.py` and implement the `affine_forward` function.\n",
    "\n",
    "Once you are done you can test your implementaion by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_forward function:\n",
      "difference:  9.769849468192957e-10\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_forward function\n",
    "\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "out, _ = affine_forward(x, w, b)\n",
    "correct_out = np.array([[ 1.49834967,  1.70660132,  1.91485297],\n",
    "                        [ 3.25553199,  3.5141327,   3.77273342]])\n",
    "\n",
    "# Compare your output with ours. The error should be around e-9 or less.\n",
    "print('Testing affine_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affine layer: backward\n",
    "Now implement the `affine_backward` function and test your implementation using numeric gradient checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_backward function:\n",
      "dx error:  5.399100368651805e-11\n",
      "dw error:  9.904211865398145e-11\n",
      "db error:  2.4122867568119087e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the affine_backward function\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 2, 3)\n",
    "w = np.random.randn(6, 5)\n",
    "b = np.random.randn(5)\n",
    "dout = np.random.randn(10, 5)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "_, cache = affine_forward(x, w, b)\n",
    "dx, dw, db = affine_backward(dout, cache)\n",
    "\n",
    "# The error should be around e-10 or less\n",
    "print('Testing affine_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU activation: forward\n",
    "Implement the forward pass for the ReLU activation function in the `relu_forward` function and test your implementation using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_forward function:\n",
      "difference:  4.999999798022158e-08\n"
     ]
    }
   ],
   "source": [
    "# Test the relu_forward function\n",
    "\n",
    "x = np.linspace(-0.5, 0.5, num=12).reshape(3, 4)\n",
    "\n",
    "out, _ = relu_forward(x)\n",
    "correct_out = np.array([[ 0.,          0.,          0.,          0.,        ],\n",
    "                        [ 0.,          0.,          0.04545455,  0.13636364,],\n",
    "                        [ 0.22727273,  0.31818182,  0.40909091,  0.5,       ]])\n",
    "\n",
    "# Compare your output with ours. The error should be on the order of e-8\n",
    "print('Testing relu_forward function:')\n",
    "print('difference: ', rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReLU activation: backward\n",
    "Now implement the backward pass for the ReLU activation function in the `relu_backward` function and test your implementation using numeric gradient checking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing relu_backward function:\n",
      "dx error:  3.2756349136310288e-12\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_forward(x)[0], x, dout)\n",
    "\n",
    "_, cache = relu_forward(x)\n",
    "dx = relu_backward(dout, cache)\n",
    "\n",
    "# The error should be on the order of e-12\n",
    "print('Testing relu_backward function:')\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 1: \n",
    "\n",
    "We've only asked you to implement ReLU, but there are a number of different activation functions that one could use in neural networks, each with its pros and cons. In particular, an issue commonly seen with activation functions is getting zero (or close to zero) gradient flow during backpropagation. Which of the following activation functions have this problem? If you consider these functions in the one dimensional case, what types of input would lead to this behaviour?\n",
    "1. Sigmoid\n",
    "2. ReLU\n",
    "3. Leaky ReLU\n",
    "\n",
    "## Answer:\n",
    "Sigmoid and ReLU would have the problem of \"gradient vanishing\", getting zero gredient. Leaky ReLU could overcome this drawback.\n",
    "Circumstance with \"gradient vanishing\" problem:\n",
    "- for Sigmoid, when $abs(input)$ is extremly large\n",
    "- for ReLU, when input is less then zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Sandwich\" layers\n",
    "There are some common patterns of layers that are frequently used in neural nets. For example, affine layers are frequently followed by a ReLU nonlinearity. To make these common patterns easy, we define several convenience layers in the file `cs231n/layer_utils.py`.\n",
    "\n",
    "For now take a look at the `affine_relu_forward` and `affine_relu_backward` functions, and run the following to numerically gradient check the backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing affine_relu_forward and affine_relu_backward:\n",
      "dx error:  2.299579177309368e-11\n",
      "dw error:  8.162011105764925e-11\n",
      "db error:  7.826724021458994e-12\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import affine_relu_forward, affine_relu_backward\n",
    "np.random.seed(231)\n",
    "x = np.random.randn(2, 3, 4)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(2, 10)\n",
    "\n",
    "out, cache = affine_relu_forward(x, w, b)\n",
    "dx, dw, db = affine_relu_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: affine_relu_forward(x, w, b)[0], x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: affine_relu_forward(x, w, b)[0], w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: affine_relu_forward(x, w, b)[0], b, dout)\n",
    "\n",
    "# Relative error should be around e-10 or less\n",
    "print('Testing affine_relu_forward and affine_relu_backward:')\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dw error: ', rel_error(dw_num, dw))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss layers: Softmax and SVM\n",
    "You implemented these loss functions in the last assignment, so we'll give them to you for free here. You should still make sure you understand how they work by looking at the implementations in `cs231n/layers.py`.\n",
    "\n",
    "You can make sure that the implementations are correct by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing svm_loss:\n",
      "loss:  8.999602749096233\n",
      "dx error:  1.4021566006651672e-09\n",
      "\n",
      "Testing softmax_loss:\n",
      "loss:  2.302545844500738\n",
      "dx error:  9.384673161989355e-09\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "num_classes, num_inputs = 10, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: svm_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = svm_loss(x, y)\n",
    "\n",
    "# Test svm_loss function. Loss should be around 9 and dx error should be around the order of e-9\n",
    "print('Testing svm_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "\n",
    "dx_num = eval_numerical_gradient(lambda x: softmax_loss(x, y)[0], x, verbose=False)\n",
    "loss, dx = softmax_loss(x, y)\n",
    "\n",
    "# Test softmax_loss function. Loss should be close to 2.3 and dx error should be around e-8\n",
    "print('\\nTesting softmax_loss:')\n",
    "print('loss: ', loss)\n",
    "print('dx error: ', rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-layer network\n",
    "In the previous assignment you implemented a two-layer neural network in a single monolithic class. Now that you have implemented modular versions of the necessary layers, you will reimplement the two layer network using these modular implementations.\n",
    "\n",
    "Open the file `cs231n/classifiers/fc_net.py` and complete the implementation of the `TwoLayerNet` class. **This class will serve as a model for the other networks you will implement in this assignment**, so read through it to make sure you understand the API. You can run the cell below to test your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Testing test-time forward pass ... \n",
      "Testing training loss (no regularization)\n",
      "Running numeric gradient check with reg =  0.0\n",
      "W1 relative error: 1.83e-08\n",
      "W2 relative error: 3.12e-10\n",
      "b1 relative error: 9.83e-09\n",
      "b2 relative error: 4.33e-10\n",
      "Running numeric gradient check with reg =  0.7\n",
      "W1 relative error: 2.53e-07\n",
      "W2 relative error: 7.98e-08\n",
      "b1 relative error: 1.56e-08\n",
      "b2 relative error: 7.76e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H, C = 3, 5, 50, 7\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "std = 1e-3\n",
    "model = TwoLayerNet(input_dim=D, hidden_dim=H, num_classes=C, weight_scale=std)\n",
    "\n",
    "print('Testing initialization ... ')\n",
    "W1_std = abs(model.params['W1'].std() - std)\n",
    "b1 = model.params['b1']\n",
    "W2_std = abs(model.params['W2'].std() - std)\n",
    "b2 = model.params['b2']\n",
    "assert W1_std < std / 10, 'First layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second layer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second layer biases do not seem right'\n",
    "\n",
    "print('Testing test-time forward pass ... ')\n",
    "model.params['W1'] = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "model.params['b1'] = np.linspace(-0.1, 0.9, num=H)\n",
    "model.params['W2'] = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "model.params['b2'] = np.linspace(-0.9, 0.1, num=C)\n",
    "X = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.loss(X)\n",
    "correct_scores = np.asarray(\n",
    "  [[11.53165108,  12.2917344,   13.05181771,  13.81190102,  14.57198434, 15.33206765,  16.09215096],\n",
    "   [12.05769098,  12.74614105,  13.43459113,  14.1230412,   14.81149128, 15.49994135,  16.18839143],\n",
    "   [12.58373087,  13.20054771,  13.81736455,  14.43418138,  15.05099822, 15.66781506,  16.2846319 ]])\n",
    "scores_diff = np.abs(scores - correct_scores).sum()\n",
    "assert scores_diff < 1e-6, 'Problem with test-time forward pass'\n",
    "\n",
    "print('Testing training loss (no regularization)')\n",
    "y = np.asarray([0, 5, 1])\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 3.4702243556\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with training-time loss'\n",
    "\n",
    "model.reg = 1.0\n",
    "loss, grads = model.loss(X, y)\n",
    "correct_loss = 26.5948426952\n",
    "assert abs(loss - correct_loss) < 1e-10, 'Problem with regularization loss'\n",
    "\n",
    "# Errors should be around e-7 or less\n",
    "for reg in [0.0, 0.7]:\n",
    "  print('Running numeric gradient check with reg = ', reg)\n",
    "  model.reg = reg\n",
    "  loss, grads = model.loss(X, y)\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver\n",
    "In the previous assignment, the logic for training models was coupled to the models themselves. Following a more modular design, for this assignment we have split the logic for training models into a separate class.\n",
    "\n",
    "Open the file `cs231n/solver.py` and read through it to familiarize yourself with the API. After doing so, use a `Solver` instance to train a `TwoLayerNet` that achieves at least `50%` accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0 / 50) train acc: 0.172327; val_acc: 0.163000\n",
      "(Epoch 1 / 50) train acc: 0.406469; val_acc: 0.399000\n",
      "(Epoch 2 / 50) train acc: 0.430776; val_acc: 0.430000\n",
      "(Epoch 3 / 50) train acc: 0.434449; val_acc: 0.401000\n",
      "(Epoch 4 / 50) train acc: 0.477837; val_acc: 0.444000\n",
      "(Iteration 1000 / 12250) loss: 1.479563\n",
      "(Epoch 5 / 50) train acc: 0.492408; val_acc: 0.458000\n",
      "(Epoch 6 / 50) train acc: 0.498408; val_acc: 0.453000\n",
      "(Epoch 7 / 50) train acc: 0.523367; val_acc: 0.457000\n",
      "(Epoch 8 / 50) train acc: 0.509837; val_acc: 0.436000\n",
      "(Iteration 2000 / 12250) loss: 1.385103\n",
      "(Epoch 9 / 50) train acc: 0.535286; val_acc: 0.460000\n",
      "(Epoch 10 / 50) train acc: 0.547653; val_acc: 0.468000\n",
      "(Epoch 11 / 50) train acc: 0.569306; val_acc: 0.483000\n",
      "(Epoch 12 / 50) train acc: 0.587796; val_acc: 0.493000\n",
      "(Iteration 3000 / 12250) loss: 1.215753\n",
      "(Epoch 13 / 50) train acc: 0.581857; val_acc: 0.484000\n",
      "(Epoch 14 / 50) train acc: 0.587041; val_acc: 0.448000\n",
      "(Epoch 15 / 50) train acc: 0.591367; val_acc: 0.463000\n",
      "(Epoch 16 / 50) train acc: 0.625204; val_acc: 0.490000\n",
      "(Iteration 4000 / 12250) loss: 1.060089\n",
      "(Epoch 17 / 50) train acc: 0.627122; val_acc: 0.483000\n",
      "(Epoch 18 / 50) train acc: 0.621143; val_acc: 0.460000\n",
      "(Epoch 19 / 50) train acc: 0.636673; val_acc: 0.488000\n",
      "(Epoch 20 / 50) train acc: 0.660816; val_acc: 0.493000\n",
      "(Iteration 5000 / 12250) loss: 1.032714\n",
      "(Epoch 21 / 50) train acc: 0.674408; val_acc: 0.494000\n",
      "(Epoch 22 / 50) train acc: 0.683122; val_acc: 0.490000\n",
      "(Epoch 23 / 50) train acc: 0.665429; val_acc: 0.456000\n",
      "(Epoch 24 / 50) train acc: 0.688633; val_acc: 0.485000\n",
      "(Iteration 6000 / 12250) loss: 0.959140\n",
      "(Epoch 25 / 50) train acc: 0.704367; val_acc: 0.476000\n",
      "(Epoch 26 / 50) train acc: 0.704939; val_acc: 0.487000\n",
      "(Epoch 27 / 50) train acc: 0.722755; val_acc: 0.480000\n",
      "(Epoch 28 / 50) train acc: 0.730306; val_acc: 0.490000\n",
      "(Iteration 7000 / 12250) loss: 0.814154\n",
      "(Epoch 29 / 50) train acc: 0.725082; val_acc: 0.469000\n",
      "(Epoch 30 / 50) train acc: 0.749714; val_acc: 0.481000\n",
      "(Epoch 31 / 50) train acc: 0.744878; val_acc: 0.488000\n",
      "(Epoch 32 / 50) train acc: 0.764041; val_acc: 0.466000\n",
      "(Iteration 8000 / 12250) loss: 0.615446\n",
      "(Epoch 33 / 50) train acc: 0.760592; val_acc: 0.469000\n",
      "(Epoch 34 / 50) train acc: 0.770469; val_acc: 0.484000\n",
      "(Epoch 35 / 50) train acc: 0.778102; val_acc: 0.482000\n",
      "(Epoch 36 / 50) train acc: 0.784102; val_acc: 0.466000\n",
      "(Iteration 9000 / 12250) loss: 0.681415\n",
      "(Epoch 37 / 50) train acc: 0.788694; val_acc: 0.466000\n",
      "(Epoch 38 / 50) train acc: 0.794673; val_acc: 0.466000\n",
      "(Epoch 39 / 50) train acc: 0.810388; val_acc: 0.453000\n",
      "(Epoch 40 / 50) train acc: 0.814735; val_acc: 0.479000\n",
      "(Iteration 10000 / 12250) loss: 0.424324\n",
      "(Epoch 41 / 50) train acc: 0.817163; val_acc: 0.482000\n",
      "(Epoch 42 / 50) train acc: 0.817327; val_acc: 0.452000\n",
      "(Epoch 43 / 50) train acc: 0.824469; val_acc: 0.464000\n",
      "(Epoch 44 / 50) train acc: 0.832245; val_acc: 0.471000\n",
      "(Iteration 11000 / 12250) loss: 0.467323\n",
      "(Epoch 45 / 50) train acc: 0.833449; val_acc: 0.465000\n",
      "(Epoch 46 / 50) train acc: 0.842102; val_acc: 0.475000\n",
      "(Epoch 47 / 50) train acc: 0.846776; val_acc: 0.470000\n",
      "(Epoch 48 / 50) train acc: 0.847449; val_acc: 0.460000\n",
      "(Iteration 12000 / 12250) loss: 0.515755\n",
      "(Epoch 49 / 50) train acc: 0.853878; val_acc: 0.458000\n",
      "(Epoch 50 / 50) train acc: 0.857184; val_acc: 0.463000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet()\n",
    "solver = None\n",
    "\n",
    "##############################################################################\n",
    "# TODO: Use a Solver instance to train a TwoLayerNet that achieves at least  #\n",
    "# 50% accuracy on the validation set.                                        #\n",
    "##############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "## configuration\n",
    "num_train = data['X_train'].shape[0]\n",
    "num_val = data['X_val'].shape[0]\n",
    "kwargs = {'update_rule':'adam', 'lr_decay':0.95, 'batch_size':200, \n",
    "         'num_epochs':50, 'num_train_samples':num_train, \n",
    "          'num_val_samples':num_val, 'print_every':1000, \n",
    "         'verbose':True}\n",
    "\n",
    "# create Solver instance\n",
    "solver = Solver(model, data, **kwargs)\n",
    "solver.train()\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to visualize training loss and train / val accuracy\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(solver.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(solver.train_acc_history, '-o', label='train')\n",
    "plt.plot(solver.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(solver.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer network\n",
    "Next you will implement a fully-connected network with an arbitrary number of hidden layers.\n",
    "\n",
    "Read through the `FullyConnectedNet` class in the file `cs231n/classifiers/fc_net.py`.\n",
    "\n",
    "Implement the initialization, the forward pass, and the backward pass. For the moment don't worry about implementing dropout or batch/layer normalization; we will add those features soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial loss and gradient check\n",
    "\n",
    "As a sanity check, run the following to check the initial loss and to gradient check the network both with and without regularization. Do the initial losses seem reasonable?\n",
    "\n",
    "For gradient checking, you should expect to see errors around 1e-7 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running check with reg =  0\n",
      "Initial loss:  2.3004790897684924\n",
      "W1 relative error: 1.48e-07\n",
      "W2 relative error: 2.21e-05\n",
      "W3 relative error: 3.53e-07\n",
      "b1 relative error: 5.38e-09\n",
      "b2 relative error: 2.09e-09\n",
      "b3 relative error: 5.80e-11\n",
      "Running check with reg =  3.14\n",
      "Initial loss:  7.052114776533016\n",
      "W1 relative error: 1.14e-08\n",
      "W2 relative error: 6.87e-08\n",
      "W3 relative error: 3.48e-08\n",
      "b1 relative error: 1.48e-08\n",
      "b2 relative error: 1.72e-09\n",
      "b3 relative error: 1.80e-10\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(231)\n",
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for reg in [0, 3.14]:\n",
    "  print('Running check with reg = ', reg)\n",
    "  model = FullyConnectedNet([H1, H2], input_dim=D, num_classes=C,\n",
    "                            reg=reg, weight_scale=5e-2, dtype=np.float64)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print('Initial loss: ', loss)\n",
    "  \n",
    "  # Most of the errors should be on the order of e-7 or smaller.   \n",
    "  # NOTE: It is fine however to see an error for W2 on the order of e-5\n",
    "  # for the check when reg = 0.0\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print('%s relative error: %.2e' % (name, rel_error(grad_num, grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another sanity check, make sure you can overfit a small dataset of 50 images. First we will try a three-layer network with 100 units in each hidden layer. In the following cell, tweak the **learning rate** and **weight initialization scale** to overfit and achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0 / 20) train acc: 0.180000; val_acc: 0.108000\n",
      "(Epoch 1 / 20) train acc: 0.320000; val_acc: 0.127000\n",
      "(Epoch 2 / 20) train acc: 0.440000; val_acc: 0.172000\n",
      "(Epoch 3 / 20) train acc: 0.500000; val_acc: 0.184000\n",
      "(Epoch 4 / 20) train acc: 0.540000; val_acc: 0.181000\n",
      "(Iteration 10 / 40) loss: 1.649552\n",
      "(Epoch 5 / 20) train acc: 0.740000; val_acc: 0.190000\n",
      "(Epoch 6 / 20) train acc: 0.740000; val_acc: 0.187000\n",
      "(Epoch 7 / 20) train acc: 0.740000; val_acc: 0.183000\n",
      "(Epoch 8 / 20) train acc: 0.820000; val_acc: 0.177000\n",
      "(Epoch 9 / 20) train acc: 0.860000; val_acc: 0.200000\n",
      "(Iteration 20 / 40) loss: 0.515392\n",
      "(Epoch 10 / 20) train acc: 0.920000; val_acc: 0.191000\n",
      "(Epoch 11 / 20) train acc: 0.960000; val_acc: 0.189000\n",
      "(Epoch 12 / 20) train acc: 0.940000; val_acc: 0.180000\n",
      "(Epoch 13 / 20) train acc: 1.000000; val_acc: 0.199000\n",
      "(Epoch 14 / 20) train acc: 1.000000; val_acc: 0.199000\n",
      "(Iteration 30 / 40) loss: 0.062867\n",
      "(Epoch 15 / 20) train acc: 1.000000; val_acc: 0.195000\n",
      "(Epoch 16 / 20) train acc: 1.000000; val_acc: 0.182000\n",
      "(Epoch 17 / 20) train acc: 1.000000; val_acc: 0.201000\n",
      "(Epoch 18 / 20) train acc: 1.000000; val_acc: 0.207000\n",
      "(Epoch 19 / 20) train acc: 1.000000; val_acc: 0.185000\n",
      "(Iteration 40 / 40) loss: 0.026844\n",
      "(Epoch 20 / 20) train acc: 1.000000; val_acc: 0.192000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use a three-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "# weight_scale = 1e-2   # Experiment with this!\n",
    "# learning_rate = 1e-4  # Experiment with this!\n",
    "weight_scale = 1e-2   # Experiment with this!\n",
    "learning_rate = 1e-2  # Experiment with this!\n",
    "model = FullyConnectedNet([100, 100],\n",
    "              weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                print_every=10, num_epochs=20, batch_size=25,\n",
    "                update_rule='sgd',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                }\n",
    "         )\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history)\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to use a five-layer network with 100 units on each layer to overfit 50 training examples. Again, you will have to adjust the learning rate and weight initialization scale, but you should be able to achieve 100% training accuracy within 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Epoch 0 / 20) train acc: 0.220000; val_acc: 0.116000\n",
      "(Epoch 1 / 20) train acc: 0.240000; val_acc: 0.083000\n",
      "(Epoch 2 / 20) train acc: 0.160000; val_acc: 0.104000\n",
      "(Epoch 3 / 20) train acc: 0.520000; val_acc: 0.106000\n",
      "(Epoch 4 / 20) train acc: 0.700000; val_acc: 0.131000\n",
      "(Iteration 10 / 40) loss: 6.303601\n",
      "(Epoch 5 / 20) train acc: 0.700000; val_acc: 0.116000\n",
      "(Epoch 6 / 20) train acc: 0.840000; val_acc: 0.114000\n",
      "(Epoch 7 / 20) train acc: 0.880000; val_acc: 0.108000\n",
      "(Epoch 8 / 20) train acc: 0.900000; val_acc: 0.109000\n",
      "(Epoch 9 / 20) train acc: 0.960000; val_acc: 0.114000\n",
      "(Iteration 20 / 40) loss: 0.412498\n",
      "(Epoch 10 / 20) train acc: 0.980000; val_acc: 0.127000\n",
      "(Epoch 11 / 20) train acc: 1.000000; val_acc: 0.126000\n",
      "(Epoch 12 / 20) train acc: 1.000000; val_acc: 0.124000\n",
      "(Epoch 13 / 20) train acc: 1.000000; val_acc: 0.124000\n",
      "(Epoch 14 / 20) train acc: 1.000000; val_acc: 0.124000\n",
      "(Iteration 30 / 40) loss: 0.001214\n",
      "(Epoch 15 / 20) train acc: 1.000000; val_acc: 0.125000\n",
      "(Epoch 16 / 20) train acc: 1.000000; val_acc: 0.125000\n",
      "(Epoch 17 / 20) train acc: 1.000000; val_acc: 0.125000\n",
      "(Epoch 18 / 20) train acc: 1.000000; val_acc: 0.125000\n",
      "(Epoch 19 / 20) train acc: 1.000000; val_acc: 0.125000\n",
      "(Iteration 40 / 40) loss: 0.003877\n",
      "(Epoch 20 / 20) train acc: 1.000000; val_acc: 0.125000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Use a five-layer Net to overfit 50 training examples by \n",
    "# tweaking just the learning rate and initialization scale.\n",
    "\n",
    "num_train = 50\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "# learning_rate = 2e-3  # Experiment with this!\n",
    "# weight_scale = 1e-5   # Experiment with this!\n",
    "learning_rate = 1e-3  # Experiment with this!\n",
    "weight_scale = 1e-1   # Experiment with this!\n",
    "\n",
    "model = FullyConnectedNet([100, 100, 100, 100],\n",
    "                        weight_scale=weight_scale, dtype=np.float64)\n",
    "solver = Solver(model, small_data,\n",
    "                        print_every=10, num_epochs=20, batch_size=25,\n",
    "                        update_rule='sgd',\n",
    "                        optim_config={'learning_rate': learning_rate}, verbose=True)\n",
    "solver.train()\n",
    "\n",
    "plt.plot(solver.loss_history)\n",
    "plt.title('Training loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 2: \n",
    "Did you notice anything about the comparative difficulty of training the three-layer net vs training the five layer net? In particular, based on your experience, which network seemed more sensitive to the initialization scale? Why do you think that is the case?\n",
    "\n",
    "## Answer:\n",
    "Five-layer net is more sensitive to parameters initialization.\n",
    "With the increase of layers, the network get deeper, meaning that small changes in the upper stream may result in great changes in output of the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update rules\n",
    "So far we have used vanilla stochastic gradient descent (SGD) as our update rule. More sophisticated update rules can make it easier to train deep networks. We will implement a few of the most commonly used update rules and compare them to vanilla SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD+Momentum\n",
    "Stochastic gradient descent with momentum is a widely used update rule that tends to make deep networks converge faster than vanilla stochastic gradient descent. See the Momentum Update section at http://cs231n.github.io/neural-networks-3/#sgd for more information.\n",
    "\n",
    "Open the file `cs231n/optim.py` and read the documentation at the top of the file to make sure you understand the API. Implement the SGD+momentum update rule in the function `sgd_momentum` and run the following to check your implementation. You should see errors less than e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  8.882347033505819e-09\n",
      "velocity error:  4.269287743278663e-09\n"
     ]
    }
   ],
   "source": [
    "from cs231n.optim import sgd_momentum\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-3, 'velocity': v}\n",
    "next_w, _ = sgd_momentum(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "# Should see relative errors around e-8 or less\n",
    "print('next_w error: ', rel_error(next_w, expected_next_w))\n",
    "print('velocity error: ', rel_error(expected_velocity, config['velocity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done so, run the following to train a six-layer network with both SGD and SGD+momentum. You should see the SGD+momentum update rule converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with  sgd\n",
      "(Epoch 0 / 5) train acc: 0.104000; val_acc: 0.107000\n",
      "(Iteration 10 / 200) loss: 2.339945\n",
      "(Iteration 20 / 200) loss: 2.175808\n",
      "(Iteration 30 / 200) loss: 2.173179\n",
      "(Iteration 40 / 200) loss: 2.221346\n",
      "(Epoch 1 / 5) train acc: 0.225000; val_acc: 0.193000\n",
      "(Iteration 50 / 200) loss: 2.093417\n",
      "(Iteration 60 / 200) loss: 2.130112\n",
      "(Iteration 70 / 200) loss: 2.011221\n",
      "(Iteration 80 / 200) loss: 2.069395\n",
      "(Epoch 2 / 5) train acc: 0.298000; val_acc: 0.260000\n",
      "(Iteration 90 / 200) loss: 2.074002\n",
      "(Iteration 100 / 200) loss: 1.978666\n",
      "(Iteration 110 / 200) loss: 1.891036\n",
      "(Iteration 120 / 200) loss: 1.776107\n",
      "(Epoch 3 / 5) train acc: 0.343000; val_acc: 0.287000\n",
      "(Iteration 130 / 200) loss: 1.945692\n",
      "(Iteration 140 / 200) loss: 1.839291\n",
      "(Iteration 150 / 200) loss: 1.743849\n",
      "(Iteration 160 / 200) loss: 1.714818\n",
      "(Epoch 4 / 5) train acc: 0.322000; val_acc: 0.305000\n",
      "(Iteration 170 / 200) loss: 1.793649\n",
      "(Iteration 180 / 200) loss: 1.859658\n",
      "(Iteration 190 / 200) loss: 1.800073\n",
      "(Iteration 200 / 200) loss: 1.881027\n",
      "(Epoch 5 / 5) train acc: 0.372000; val_acc: 0.319000\n",
      "\n",
      "running with  sgd_momentum\n",
      "(Epoch 0 / 5) train acc: 0.099000; val_acc: 0.088000\n",
      "(Iteration 10 / 200) loss: 2.240157\n",
      "(Iteration 20 / 200) loss: 2.056244\n",
      "(Iteration 30 / 200) loss: 1.945149\n",
      "(Iteration 40 / 200) loss: 1.903534\n",
      "(Epoch 1 / 5) train acc: 0.308000; val_acc: 0.258000\n",
      "(Iteration 50 / 200) loss: 1.798500\n",
      "(Iteration 60 / 200) loss: 1.985626\n",
      "(Iteration 70 / 200) loss: 1.826820\n",
      "(Iteration 80 / 200) loss: 1.660931\n",
      "(Epoch 2 / 5) train acc: 0.377000; val_acc: 0.331000\n",
      "(Iteration 90 / 200) loss: 1.701757\n",
      "(Iteration 100 / 200) loss: 1.620104\n",
      "(Iteration 110 / 200) loss: 1.674644\n",
      "(Iteration 120 / 200) loss: 1.447811\n",
      "(Epoch 3 / 5) train acc: 0.469000; val_acc: 0.335000\n",
      "(Iteration 130 / 200) loss: 1.484753\n",
      "(Iteration 140 / 200) loss: 1.504798\n",
      "(Iteration 150 / 200) loss: 1.424480\n",
      "(Iteration 160 / 200) loss: 1.492736\n",
      "(Epoch 4 / 5) train acc: 0.483000; val_acc: 0.356000\n",
      "(Iteration 170 / 200) loss: 1.351984\n",
      "(Iteration 180 / 200) loss: 1.522500\n",
      "(Iteration 190 / 200) loss: 1.470634\n",
      "(Iteration 200 / 200) loss: 1.306531\n",
      "(Epoch 5 / 5) train acc: 0.505000; val_acc: 0.361000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/anaconda3/envs/cs231n_2/lib/python3.7/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_train = 4000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "\n",
    "for update_rule in ['sgd', 'sgd_momentum']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': 5e-3,\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in solvers.items():\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=\"loss_%s\" % update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=\"train_acc_%s\" % update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=\"val_acc_%s\" % update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp and Adam\n",
    "RMSProp [1] and Adam [2] are update rules that set per-parameter learning rates by using a running average of the second moments of gradients.\n",
    "\n",
    "In the file `cs231n/optim.py`, implement the RMSProp update rule in the `rmsprop` function and implement the Adam update rule in the `adam` function, and check your implementations using the tests below.\n",
    "\n",
    "**NOTE:** Please implement the _complete_ Adam update rule (with the bias correction mechanism), not the first simplified version mentioned in the course notes. \n",
    "\n",
    "[1] Tijmen Tieleman and Geoffrey Hinton. \"Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning 4 (2012).\n",
    "\n",
    "[2] Diederik Kingma and Jimmy Ba, \"Adam: A Method for Stochastic Optimization\", ICLR 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  9.524687511038133e-08\n",
      "cache error:  2.6477955807156126e-09\n"
     ]
    }
   ],
   "source": [
    "# Test RMSProp implementation\n",
    "from cs231n.optim import rmsprop\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'cache': cache}\n",
    "next_w, _ = rmsprop(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('cache error: ', rel_error(expected_cache, config['cache']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_w error:  1.1395691798535431e-07\n",
      "v error:  4.208314038113071e-09\n",
      "m error:  4.214963193114416e-09\n"
     ]
    }
   ],
   "source": [
    "# Test Adam implementation\n",
    "from cs231n.optim import adam\n",
    "\n",
    "N, D = 4, 5\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "config = {'learning_rate': 1e-2, 'm': m, 'v': v, 't': 5}\n",
    "next_w, _ = adam(w, dw, config=config)\n",
    "\n",
    "expected_next_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "# You should see relative errors around e-7 or less\n",
    "print('next_w error: ', rel_error(expected_next_w, next_w))\n",
    "print('v error: ', rel_error(expected_v, config['v']))\n",
    "print('m error: ', rel_error(expected_m, config['m']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have debugged your RMSProp and Adam implementations, run the following to train a pair of deep networks using these new update rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with  adam\n",
      "(Epoch 0 / 5) train acc: 0.126000; val_acc: 0.110000\n",
      "(Iteration 10 / 200) loss: 1.988385\n",
      "(Iteration 20 / 200) loss: 1.927173\n",
      "(Iteration 30 / 200) loss: 1.834488\n",
      "(Iteration 40 / 200) loss: 1.711647\n",
      "(Epoch 1 / 5) train acc: 0.363000; val_acc: 0.330000\n",
      "(Iteration 50 / 200) loss: 1.709190\n",
      "(Iteration 60 / 200) loss: 1.654181\n",
      "(Iteration 70 / 200) loss: 1.592772\n",
      "(Iteration 80 / 200) loss: 1.780636\n",
      "(Epoch 2 / 5) train acc: 0.416000; val_acc: 0.362000\n",
      "(Iteration 90 / 200) loss: 1.344151\n",
      "(Iteration 100 / 200) loss: 1.469709\n",
      "(Iteration 110 / 200) loss: 1.324871\n",
      "(Iteration 120 / 200) loss: 1.193847\n",
      "(Epoch 3 / 5) train acc: 0.496000; val_acc: 0.374000\n",
      "(Iteration 130 / 200) loss: 1.509649\n",
      "(Iteration 140 / 200) loss: 1.423628\n",
      "(Iteration 150 / 200) loss: 1.247283\n",
      "(Iteration 160 / 200) loss: 1.133567\n",
      "(Epoch 4 / 5) train acc: 0.512000; val_acc: 0.345000\n",
      "(Iteration 170 / 200) loss: 1.233204\n",
      "(Iteration 180 / 200) loss: 1.317085\n",
      "(Iteration 190 / 200) loss: 1.349817\n",
      "(Iteration 200 / 200) loss: 1.502092\n",
      "(Epoch 5 / 5) train acc: 0.554000; val_acc: 0.382000\n",
      "\n",
      "running with  rmsprop\n",
      "(Epoch 0 / 5) train acc: 0.119000; val_acc: 0.146000\n",
      "(Iteration 10 / 200) loss: 2.075767\n",
      "(Iteration 20 / 200) loss: 2.077587\n",
      "(Iteration 30 / 200) loss: 1.741490\n",
      "(Iteration 40 / 200) loss: 1.898407\n",
      "(Epoch 1 / 5) train acc: 0.382000; val_acc: 0.326000\n",
      "(Iteration 50 / 200) loss: 1.711864\n",
      "(Iteration 60 / 200) loss: 1.809976\n",
      "(Iteration 70 / 200) loss: 1.696386\n",
      "(Iteration 80 / 200) loss: 1.787341\n",
      "(Epoch 2 / 5) train acc: 0.434000; val_acc: 0.341000\n",
      "(Iteration 90 / 200) loss: 1.621025\n",
      "(Iteration 100 / 200) loss: 1.442351\n",
      "(Iteration 110 / 200) loss: 1.459296\n",
      "(Iteration 120 / 200) loss: 1.536740\n",
      "(Epoch 3 / 5) train acc: 0.471000; val_acc: 0.365000\n",
      "(Iteration 130 / 200) loss: 1.331889\n",
      "(Iteration 140 / 200) loss: 1.330509\n",
      "(Iteration 150 / 200) loss: 1.412984\n",
      "(Iteration 160 / 200) loss: 1.465931\n",
      "(Epoch 4 / 5) train acc: 0.515000; val_acc: 0.364000\n",
      "(Iteration 170 / 200) loss: 1.537309\n",
      "(Iteration 180 / 200) loss: 1.394434\n",
      "(Iteration 190 / 200) loss: 1.244834\n",
      "(Iteration 200 / 200) loss: 1.442645\n",
      "(Epoch 5 / 5) train acc: 0.528000; val_acc: 0.369000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = {'rmsprop': 1e-4, 'adam': 1e-3}\n",
    "for update_rule in ['adam', 'rmsprop']:\n",
    "  print('running with ', update_rule)\n",
    "  model = FullyConnectedNet([100, 100, 100, 100, 100], weight_scale=5e-2)\n",
    "\n",
    "  solver = Solver(model, small_data,\n",
    "                  num_epochs=5, batch_size=100,\n",
    "                  update_rule=update_rule,\n",
    "                  optim_config={\n",
    "                    'learning_rate': learning_rates[update_rule]\n",
    "                  },\n",
    "                  verbose=True)\n",
    "  solvers[update_rule] = solver\n",
    "  solver.train()\n",
    "  print()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "for update_rule, solver in list(solvers.items()):\n",
    "  plt.subplot(3, 1, 1)\n",
    "  plt.plot(solver.loss_history, 'o', label=update_rule)\n",
    "  \n",
    "  plt.subplot(3, 1, 2)\n",
    "  plt.plot(solver.train_acc_history, '-o', label=update_rule)\n",
    "\n",
    "  plt.subplot(3, 1, 3)\n",
    "  plt.plot(solver.val_acc_history, '-o', label=update_rule)\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "## Inline Question 3:\n",
    "\n",
    "AdaGrad, like Adam, is a per-parameter optimization method that uses the following update rule:\n",
    "\n",
    "```\n",
    "cache += dw**2\n",
    "w += - learning_rate * dw / (np.sqrt(cache) + eps)\n",
    "```\n",
    "\n",
    "John notices that when he was training a network with AdaGrad that the updates became very small, and that his network was learning slowly. Using your knowledge of the AdaGrad update rule, why do you think the updates would become very small? Would Adam have the same issue?\n",
    "\n",
    "\n",
    "## Answer: \n",
    "\"cache\" is accumulated dw\\**2, with the training process goes on, \"cache\" get larger, therefore, the weights update is too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a good model!\n",
    "Train the best fully-connected model that you can on CIFAR-10, storing your best model in the `best_model` variable. We require you to get at least 50% accuracy on the validation set using a fully-connected net.\n",
    "\n",
    "If you are careful it should be possible to get accuracies above 55%, but we don't require it for this part and won't assign extra credit for doing so. Later in the assignment we will ask you to train the best convolutional network that you can on CIFAR-10, and we would prefer that you spend your effort working on convolutional nets rather than fully-connected nets.\n",
    "\n",
    "You might find it useful to complete the `BatchNormalization.ipynb` and `Dropout.ipynb` notebooks before completing this part, since those techniques can help you train powerful models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters tunning:\n",
      "num_hidden:  [5]\n",
      "weight_scale:  [1.e-09 1.e-08 1.e-07 1.e-06 1.e-05 1.e-04 1.e-03 1.e-02]\n",
      "learning_rate:  [1.e-07 1.e-06 1.e-05 1.e-04 1.e-03 1.e-02]\n",
      "regularization:  [1.e-06 1.e-05 1.e-04 1.e-03 1.e-02 1.e-01 1.e+01 3.e+01 5.e+01 7.e+01\n",
      " 9.e+01]\n",
      "(test 1/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.087000\n",
      "best val_acc of the best model: 0.000000\n",
      "\n",
      "(test 2/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.087000\n",
      "\n",
      "(test 3/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.116000\n",
      "\n",
      "(test 4/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.116000\n",
      "\n",
      "(test 5/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.116000\n",
      "\n",
      "(test 6/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.119000\n",
      "\n",
      "(test 7/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.119000\n",
      "\n",
      "(test 8/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 9/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.092000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 10/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 11/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 12/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 13/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 14/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 15/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 16/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 17/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 18/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 19/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 20/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 21/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 22/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 23/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 24/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 25/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 26/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 27/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 28/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 29/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 30/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 31/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 32/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 33/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 34/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 35/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 36/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 37/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 38/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 39/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 40/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 41/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 42/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 43/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 44/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.146000\n",
      "best val_acc of the best model: 0.145000\n",
      "\n",
      "(test 45/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.146000\n",
      "\n",
      "(test 46/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.177000\n",
      "\n",
      "(test 47/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.180000\n",
      "\n",
      "(test 48/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.182000\n",
      "\n",
      "(test 49/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.185000\n",
      "\n",
      "(test 50/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.185000\n",
      "\n",
      "(test 51/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.185000\n",
      "\n",
      "(test 52/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.188000\n",
      "\n",
      "(test 53/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.190000\n",
      "best val_acc of the best model: 0.188000\n",
      "\n",
      "(test 54/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.190000\n",
      "\n",
      "(test 55/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.190000\n",
      "\n",
      "(test 56/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.175000\n",
      "best val_acc of the best model: 0.190000\n",
      "\n",
      "(test 57/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.169000\n",
      "best val_acc of the best model: 0.190000\n",
      "\n",
      "(test 58/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.190000\n",
      "\n",
      "(test 59/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 60/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 61/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 62/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 63/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 64/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 65/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 66/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.191000\n",
      "\n",
      "(test 67/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 68/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 69/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 70/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 71/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 72/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 73/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 74/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 75/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 76/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 77/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 78/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 79/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 80/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 81/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 82/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 83/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 84/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 85/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 86/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 87/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 88/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 89/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 90/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 91/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 92/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 93/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 94/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 95/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 96/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 97/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 98/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.168000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 99/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 100/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 101/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 102/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 103/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 104/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 105/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 106/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 107/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 108/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 109/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 110/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 111/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 112/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 113/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 114/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 115/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 116/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 117/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.175000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 118/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 119/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 120/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 121/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 122/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 123/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 124/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 125/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 126/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 127/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.193000\n",
      "\n",
      "(test 128/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.198000\n",
      "\n",
      "(test 129/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 130/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 131/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 132/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 133/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 134/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 135/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 136/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 137/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 138/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 139/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.150000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 140/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 141/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 142/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 143/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 144/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 145/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 146/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 147/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 148/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 149/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 150/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 151/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 152/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 153/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 154/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 155/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 156/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 157/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 158/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 159/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 160/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 161/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.139000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 162/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.169000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 163/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 164/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.190000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 165/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 166/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 167/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 168/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 169/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 170/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 171/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 172/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 173/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 174/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 175/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 176/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 177/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 178/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.169000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 179/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 180/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 181/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 182/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 183/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 184/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 185/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 186/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.175000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 187/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.168000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 188/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.175000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 189/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 190/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 191/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.165000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 192/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 193/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 194/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 195/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 196/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 197/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 198/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 199/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 200/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 201/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 202/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 203/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 204/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 205/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 206/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.081000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 207/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 208/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 209/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 210/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 211/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 212/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 213/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 214/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 215/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 216/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 217/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 218/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 219/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 220/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.161000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 221/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 222/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 223/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 224/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 225/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 226/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 227/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 228/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 229/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 230/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 231/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 232/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 233/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 234/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 235/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 236/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 237/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 238/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 239/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 240/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 241/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 242/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 243/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 244/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 245/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 246/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 247/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 248/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 249/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 250/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 251/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 252/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 253/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 254/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 255/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 256/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 257/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 258/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 259/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 260/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 261/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 262/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 263/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 264/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 265/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 266/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 267/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 268/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.156000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 269/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 270/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 271/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.156000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 272/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 273/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 274/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 275/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 276/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 277/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 278/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 279/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 280/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 281/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 282/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 283/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 284/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 285/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.190000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 286/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 287/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 288/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 289/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 290/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 291/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 292/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 293/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 294/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 295/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 296/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 297/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.144000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 298/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 299/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 300/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 301/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 302/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 303/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 304/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 305/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 306/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 307/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 308/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 309/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 310/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 311/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 312/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 313/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 314/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 315/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 316/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 317/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 318/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 319/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 320/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 321/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 322/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 323/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 324/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 325/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 326/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 327/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.154000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 328/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 329/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 330/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 331/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 332/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 333/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 334/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 335/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 336/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 337/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 338/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 339/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 340/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 341/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 342/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 343/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 344/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 345/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 346/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 347/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 348/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 349/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 350/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 351/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 352/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 353/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 354/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 355/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 356/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 357/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 358/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.150000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 359/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 360/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 361/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 362/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 363/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 364/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 365/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 366/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 367/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 368/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 369/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 370/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 371/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 372/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 373/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 374/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 375/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 376/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 377/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 378/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.155000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 379/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 380/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 381/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 382/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 383/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 384/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 385/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 386/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 387/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 388/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 389/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 390/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 391/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 392/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 393/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 394/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 395/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 396/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 397/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 398/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 399/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.090000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 400/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 401/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 402/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 403/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 404/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 405/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 406/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 407/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 408/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 409/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 410/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 411/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 412/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 413/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 414/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.087000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 415/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 416/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.080000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 417/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 418/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 419/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 420/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 421/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 422/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 423/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 424/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 425/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 426/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 427/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 428/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 429/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 430/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 431/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 432/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 433/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 434/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 435/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 436/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 437/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 438/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 439/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 440/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 441/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 442/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 443/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 444/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.139000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 445/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 446/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 447/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 448/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 449/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 450/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 451/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 452/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 453/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 454/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 455/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 456/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 457/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 458/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 459/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.206000\n",
      "\n",
      "(test 460/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 461/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 462/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 463/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 464/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 465/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.082000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 466/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 467/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 468/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 469/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 470/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 471/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 472/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 473/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 474/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 475/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 476/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 477/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 478/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 479/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 480/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 481/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 482/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 483/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 484/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 485/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 486/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 487/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 488/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 489/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 490/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 491/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 492/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 493/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 494/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 495/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 496/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 497/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 498/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 499/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 500/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 501/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 502/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 503/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 504/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 505/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 506/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 507/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.168000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 508/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 509/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 510/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 511/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 512/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.168000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 513/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 514/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 515/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 516/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 517/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 518/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 519/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 520/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 521/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 522/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 523/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 524/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 525/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 526/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 527/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.190000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 528/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.100000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 529/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 530/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 531/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 532/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 533/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 534/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 535/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 536/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 537/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 538/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 539/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 540/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 541/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 542/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 543/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 544/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 545/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.137000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 546/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 547/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 548/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 549/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 550/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 551/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 552/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 553/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 554/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 555/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 556/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 557/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.146000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 558/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 559/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 560/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 561/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 562/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 563/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 564/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 565/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 566/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 567/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 568/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 569/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 570/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 571/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 572/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 573/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.209000\n",
      "\n",
      "(test 574/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 575/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 576/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 577/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 578/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 579/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 580/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 581/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 582/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 583/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 584/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 585/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 586/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.223000\n",
      "\n",
      "(test 587/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.224000\n",
      "\n",
      "(test 588/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.224000\n",
      "\n",
      "(test 589/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.224000\n",
      "\n",
      "(test 590/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.224000\n",
      "\n",
      "(test 591/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.225000\n",
      "\n",
      "(test 592/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.225000\n",
      "\n",
      "(test 593/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.225000\n",
      "\n",
      "(test 594/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.225000\n",
      "\n",
      "(test 595/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 596/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 597/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 598/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 599/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 600/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 601/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 602/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 603/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 604/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 605/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 606/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 607/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 608/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 609/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 610/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 611/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 612/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 613/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 614/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 615/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 616/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 617/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 618/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 619/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 620/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 621/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 622/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 623/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 624/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 625/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 626/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 627/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 628/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 629/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 630/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 631/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 632/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 633/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 634/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 635/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 636/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 637/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 638/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 639/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 640/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 641/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 642/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.270000\n",
      "best val_acc of the best model: 0.226000\n",
      "\n",
      "(test 643/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 644/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 645/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 646/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 647/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 648/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 649/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 650/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 651/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 652/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 653/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 654/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 655/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 656/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 657/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 658/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 659/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 660/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 661/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 662/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 663/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 664/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 665/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 666/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 667/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 668/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 669/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 670/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 671/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 672/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 673/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 674/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 675/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.139000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 676/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 677/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 678/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 679/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 680/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 681/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.080000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 682/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 683/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 684/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 685/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 686/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 687/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 688/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 689/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 690/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 691/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 692/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.077000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 693/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 694/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 695/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 696/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 697/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 698/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 699/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 700/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 701/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 702/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 703/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 704/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 705/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 706/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 707/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 708/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 709/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 710/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 711/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 712/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 713/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 714/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 715/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 716/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 717/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 718/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 719/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 720/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 721/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 722/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 723/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 724/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 725/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 726/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 727/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 728/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 729/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 730/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.078000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 731/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 732/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 733/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 734/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 735/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 736/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 737/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 738/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 739/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 740/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 741/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 742/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 743/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 744/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 745/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 746/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 747/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 748/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 749/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 750/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 751/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 752/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 753/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 754/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 755/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 756/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 757/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 758/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 759/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 760/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 761/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 762/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 763/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 764/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 765/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 766/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 767/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 768/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 769/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 770/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 771/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 772/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 773/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 774/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 775/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 776/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 777/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 778/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 779/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 780/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 781/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 782/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 783/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 784/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 785/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 786/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 787/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 788/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 789/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 790/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 791/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 792/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 793/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 794/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.156000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 795/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.154000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 796/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 797/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 798/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 799/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 800/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 801/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 802/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 803/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.150000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 804/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 805/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 806/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 807/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 808/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 809/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 810/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 811/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 812/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 813/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 814/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 815/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 816/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 817/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 818/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 819/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 820/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 821/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 822/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 823/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 824/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 825/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 826/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 827/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 828/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 829/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 830/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 831/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 832/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 833/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 834/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 835/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 836/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 837/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 838/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 839/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 840/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 841/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 842/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 843/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 844/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 845/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 846/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 847/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 848/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 849/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 850/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 851/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 852/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 853/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 854/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 855/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 856/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 857/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 858/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 859/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 860/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.165000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 861/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.139000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 862/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 863/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 864/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 865/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 866/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.149000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 867/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 868/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 869/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 870/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 871/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 872/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 873/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 874/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 875/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 876/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 877/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 878/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 879/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 880/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 881/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 882/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 883/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 884/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 885/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 886/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 887/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 888/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 889/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 890/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 891/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 892/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 893/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 894/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 895/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 896/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 897/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 898/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 899/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 900/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 901/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 902/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 903/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 904/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 905/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 906/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 907/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.257000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 908/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 909/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 910/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 911/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 912/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 913/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 914/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 915/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 916/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 917/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 918/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 919/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 920/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 921/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 922/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 923/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 924/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 925/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 926/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 927/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 928/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 929/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 930/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 931/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 932/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 933/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 934/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 935/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 936/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 937/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 938/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 939/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 940/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 941/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 942/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 943/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 944/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 945/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 946/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 947/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 948/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 949/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 950/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 951/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 952/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 953/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 954/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 955/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 956/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 957/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 958/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 959/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 960/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 961/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 962/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 963/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 964/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 965/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 966/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 967/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 968/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 969/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 970/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 971/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 972/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 973/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 974/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 975/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 976/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 977/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 978/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 979/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 980/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 981/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 982/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 983/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 984/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 985/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 986/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 987/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 988/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 989/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 990/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 991/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 992/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 993/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 994/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 995/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 996/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 997/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 998/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 999/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1000/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1001/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1002/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1003/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1004/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1005/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1006/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1007/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1008/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1009/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1010/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1011/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1012/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1013/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1014/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1015/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1016/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1017/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1018/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1019/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1020/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1021/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1022/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1023/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1024/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1025/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1026/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1027/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1028/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1029/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1030/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1031/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1032/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1033/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1034/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1035/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.150000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1036/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1037/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.146000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1038/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1039/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1040/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1041/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1042/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1043/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1044/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1045/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1046/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1047/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1048/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1049/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1050/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1051/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1052/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1053/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1054/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1055/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1056/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.200000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1057/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1058/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1059/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1060/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1061/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1062/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1063/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1064/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1065/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1066/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1067/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1068/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1069/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1070/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1071/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1072/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1073/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1074/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1075/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1076/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1077/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1078/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1079/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1080/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1081/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1082/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1083/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1084/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1085/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1086/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1087/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1088/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1089/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1090/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1091/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1092/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1093/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1094/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1095/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1096/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1097/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1098/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1099/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1100/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1101/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.270000\n",
      "\n",
      "(test 1102/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1103/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.242000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1104/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1105/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1106/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1107/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1108/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1109/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1110/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1111/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1112/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1113/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1114/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1115/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1116/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1117/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1118/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1119/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1120/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1121/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1122/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1123/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1124/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1125/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1126/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1127/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1128/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1129/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1130/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1131/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1132/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1133/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1134/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1135/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1136/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1137/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1138/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1139/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1140/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1141/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1142/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1143/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1144/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1145/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1146/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1147/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1148/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1149/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1150/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1151/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1152/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1153/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1154/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1155/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.082000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1156/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1157/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1158/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1159/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1160/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1161/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1162/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1163/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1164/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1165/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1166/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1167/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1168/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1169/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.272000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1170/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1171/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1172/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1173/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1174/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.305000\n",
      "best val_acc of the best model: 0.301000\n",
      "\n",
      "(test 1175/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.309000\n",
      "best val_acc of the best model: 0.305000\n",
      "\n",
      "(test 1176/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1177/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1178/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1179/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1180/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1181/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1182/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1183/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1184/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1185/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1186/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1187/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1188/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1189/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1190/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1191/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1192/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1193/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1194/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1195/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1196/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1197/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1198/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1199/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1200/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1201/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1202/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1203/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1204/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1205/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1206/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1207/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1208/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1209/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1210/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1211/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1212/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1213/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1214/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1215/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1216/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1217/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1218/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1219/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1220/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1221/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1222/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1223/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1224/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1225/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1226/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1227/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1228/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1229/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1230/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1231/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1232/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1233/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.313000\n",
      "best val_acc of the best model: 0.309000\n",
      "\n",
      "(test 1234/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.313000\n",
      "\n",
      "(test 1235/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.313000\n",
      "\n",
      "(test 1236/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.313000\n",
      "\n",
      "(test 1237/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1238/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1239/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1240/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1241/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.309000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1242/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1243/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1244/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1245/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1246/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1247/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1248/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1249/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1250/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1251/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1252/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1253/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1254/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1255/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1256/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1257/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1258/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1259/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1260/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1261/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1262/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1263/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1264/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1265/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1266/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1267/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1268/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1269/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1270/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1271/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1272/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1273/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1274/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1275/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1276/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.144000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1277/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1278/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1279/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1280/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1281/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1282/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1283/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1284/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1285/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1286/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1287/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1288/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1289/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1290/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1291/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1292/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1293/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1294/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1295/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1296/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1297/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1298/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1299/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1300/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1301/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1302/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1303/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1304/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1305/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1306/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1307/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1308/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1309/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1310/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1311/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1312/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.278000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1313/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1314/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1315/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.275000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1316/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1317/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1318/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1319/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1320/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1321/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1322/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1323/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1324/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1325/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1326/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1327/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1328/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1329/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1330/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1331/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1332/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1333/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1334/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1335/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1336/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1337/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1338/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1339/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1340/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1341/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1342/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1343/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1344/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1345/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1346/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1347/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1348/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1349/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1350/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1351/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1352/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1353/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1354/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1355/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1356/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1357/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1358/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1359/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1360/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1361/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1362/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1363/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1364/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1365/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1366/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1367/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1368/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1369/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.304000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1370/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.300000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1371/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1372/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1373/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1374/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1375/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.302000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1376/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1377/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1378/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.308000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1379/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1380/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1381/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1382/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.264000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1383/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1384/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1385/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.309000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1386/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1387/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1388/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.154000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1389/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1390/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1391/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.169000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1392/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.142000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1393/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.176000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1394/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.161000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1395/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1396/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1397/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1398/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1399/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1400/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1401/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1402/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1403/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1404/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1405/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1406/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1407/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1408/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1409/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1410/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1411/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1412/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1413/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1414/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1415/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1416/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1417/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1418/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1419/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1420/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.254000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1421/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1422/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1423/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1424/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1425/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1426/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1427/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1428/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1429/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1430/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1431/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1432/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1433/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.271000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1434/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1435/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1436/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1437/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1438/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1439/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1440/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.304000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1441/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1442/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1443/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1444/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.262000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1445/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1446/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1447/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1448/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1449/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1450/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1451/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1452/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1453/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1454/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1455/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1456/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1457/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1458/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1459/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1460/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1461/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1462/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1463/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1464/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1465/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1466/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1467/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1468/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1469/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1470/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1471/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1472/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1473/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1474/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1475/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1476/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.185000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1477/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1478/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1479/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1480/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1481/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.161000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1482/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1483/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1484/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1485/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.151000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1486/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1487/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.258000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1488/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1489/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1490/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1491/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1492/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1493/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.270000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1494/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1495/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1496/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1497/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1498/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.272000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1499/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1500/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1501/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1502/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1503/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1504/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1505/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.298000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1506/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.306000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1507/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.311000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1508/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.257000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1509/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1510/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.282000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1511/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.271000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1512/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1513/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1514/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.284000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1515/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1516/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1517/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.275000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1518/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1519/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1520/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1521/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.080000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1522/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1523/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1524/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1525/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1526/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1527/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1528/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1529/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1530/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1531/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1532/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1533/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1534/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1535/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1536/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.088000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1537/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1538/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1539/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1540/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1541/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1542/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1543/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1544/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1545/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1546/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1547/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1548/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.146000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1549/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1550/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1551/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1552/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1553/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1554/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1555/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1556/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1557/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1558/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1559/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1560/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1561/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1562/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1563/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.268000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1564/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1565/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1566/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1567/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.250000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1568/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1569/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1570/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.286000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1571/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1572/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1573/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1574/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1575/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.272000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1576/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.263000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1577/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.271000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1578/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.278000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1579/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.265000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1580/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1581/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1582/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1583/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1584/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.300000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1585/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1586/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1587/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1588/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1589/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1590/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1591/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1592/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1593/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1594/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1595/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1596/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1597/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1598/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1599/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1600/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1601/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1602/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1603/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1604/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1605/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1606/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1607/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1608/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1609/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1610/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1611/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1612/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1613/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1614/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1615/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1616/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1617/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1618/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1619/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1620/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1621/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1622/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1623/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1624/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1625/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1626/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1627/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.079000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1628/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1629/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.316000\n",
      "\n",
      "(test 1630/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1631/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.339000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1632/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.344000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1633/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.358000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1634/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.306000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1635/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.364000\n",
      "best val_acc of the best model: 0.363000\n",
      "\n",
      "(test 1636/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.364000\n",
      "\n",
      "(test 1637/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.364000\n",
      "\n",
      "(test 1638/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.347000\n",
      "best val_acc of the best model: 0.364000\n",
      "\n",
      "(test 1639/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.373000\n",
      "best val_acc of the best model: 0.364000\n",
      "\n",
      "(test 1640/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1641/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1642/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1643/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.313000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1644/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.308000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1645/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.300000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1646/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.327000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1647/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.339000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1648/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.317000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1649/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.331000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1650/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.324000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1651/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1652/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1653/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1654/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1655/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1656/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1657/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1658/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1659/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1660/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1661/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1662/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1663/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.086000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1664/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1665/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1666/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.080000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1667/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1668/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1669/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1670/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1671/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1672/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1673/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1674/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1675/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1676/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1677/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1678/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1679/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1680/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1681/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1682/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1683/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.160000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1684/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1685/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1686/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.258000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1687/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1688/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.315000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1689/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1690/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1691/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1692/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1693/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.323000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1694/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1695/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.348000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1696/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.373000\n",
      "\n",
      "(test 1697/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1698/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1699/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1700/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.332000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1701/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1702/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1703/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.371000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1704/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1705/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.352000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1706/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1707/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1708/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.319000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1709/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.324000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1710/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.324000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1711/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.332000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1712/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.329000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1713/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.322000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1714/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.315000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1715/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.317000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1716/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1717/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1718/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1719/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1720/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1721/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1722/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1723/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1724/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1725/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1726/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1727/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.092000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1728/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1729/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1730/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1731/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1732/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1733/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1734/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1735/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1736/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1737/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1738/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1739/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1740/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1741/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1742/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1743/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1744/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1745/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1746/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1747/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1748/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1749/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1750/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1751/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.304000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1752/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1753/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1754/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1755/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.325000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1756/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1757/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1758/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.329000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1759/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.325000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1760/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.264000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1761/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1762/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.392000\n",
      "best val_acc of the best model: 0.379000\n",
      "\n",
      "(test 1763/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1764/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.388000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1765/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1766/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1767/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1768/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.364000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1769/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.372000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1770/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.372000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1771/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.365000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1772/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.341000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1773/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1774/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1775/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1776/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.358000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1777/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1778/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.329000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1779/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1780/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1781/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1782/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.344000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1783/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1784/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1785/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1786/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1787/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1788/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1789/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1790/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1791/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1792/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1793/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1794/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1795/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1796/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1797/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1798/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1799/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1800/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1801/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1802/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1803/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1804/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1805/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1806/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1807/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1808/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1809/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1810/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1811/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1812/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1813/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1814/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1815/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1816/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1817/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1818/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1819/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.305000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1820/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1821/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1822/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1823/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1824/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.315000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1825/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.322000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1826/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1827/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1828/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.382000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1829/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1830/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1831/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1832/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1833/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.353000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1834/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1835/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1836/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.385000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1837/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.387000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1838/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1839/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.371000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1840/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.365000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1841/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.390000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1842/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.380000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1843/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.347000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1844/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.347000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1845/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1846/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1847/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.340000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1848/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1849/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1850/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1851/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1852/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1853/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1854/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1855/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1856/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1857/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1858/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1859/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1860/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1861/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1862/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1863/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1864/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1865/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1866/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1867/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1868/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1869/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1870/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1871/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1872/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1873/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1874/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1875/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1876/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1877/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1878/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1879/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1880/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1881/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1882/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.304000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1883/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1884/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1885/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1886/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.308000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1887/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1888/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.265000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1889/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.318000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1890/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.286000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1891/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1892/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1893/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1894/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.382000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1895/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.364000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1896/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1897/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1898/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1899/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1900/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1901/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1902/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1903/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1904/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.357000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1905/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1906/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.340000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1907/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1908/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.352000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1909/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.332000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1910/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1911/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1912/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.378000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1913/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1914/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.390000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1915/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1916/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1917/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1918/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1919/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1920/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1921/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1922/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1923/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1924/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.156000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1925/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1926/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1927/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1928/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1929/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1930/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1931/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1932/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1933/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1934/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1935/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1936/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1937/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1938/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1939/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1940/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1941/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1942/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1943/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1944/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1945/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1946/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1947/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1948/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.302000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1949/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.323000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1950/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1951/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1952/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.307000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1953/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1954/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1955/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.278000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1956/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.332000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1957/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1958/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1959/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.378000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1960/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.365000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1961/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1962/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.345000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1963/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.370000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1964/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.400000\n",
      "best val_acc of the best model: 0.392000\n",
      "\n",
      "(test 1965/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.369000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1966/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1967/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1968/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.378000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1969/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.383000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1970/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1971/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1972/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.357000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1973/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.334000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1974/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.350000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1975/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.369000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 1976/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.388000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1977/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1978/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.346000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1979/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1980/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1981/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1982/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1983/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1984/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1985/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1986/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1987/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1988/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1989/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1990/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1991/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1992/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1993/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1994/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1995/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.188000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1996/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1997/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1998/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 1999/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.173000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2000/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2001/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2002/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2003/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2004/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2005/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2006/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2007/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2008/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2009/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2010/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2011/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2012/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2013/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2014/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.300000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2015/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2016/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.321000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2017/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.308000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2018/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2019/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2020/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.305000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2021/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2022/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.311000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2023/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.326000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2024/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.317000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2025/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.369000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2026/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.380000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2027/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2028/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.383000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2029/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2030/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.373000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2031/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.357000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2032/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2033/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.348000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2034/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2035/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.391000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2036/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.384000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2037/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2038/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.367000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2039/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.343000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2040/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2041/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2042/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.385000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2043/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.332000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2044/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.389000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2045/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2046/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2047/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2048/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2049/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2050/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2051/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2052/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2053/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2054/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2055/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.088000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2056/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2057/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2058/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2059/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.087000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2060/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2061/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2062/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2063/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.154000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2064/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2065/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2066/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2067/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2068/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2069/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2070/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.171000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2071/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.148000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2072/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2073/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.153000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2074/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.155000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2075/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2076/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2077/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2078/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2079/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2080/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2081/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2082/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.254000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2083/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2084/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2085/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2086/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2087/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2088/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2089/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2090/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2091/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.339000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2092/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2093/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2094/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.343000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2095/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.345000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2096/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2097/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2098/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.370000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2099/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.378000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2100/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2101/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2102/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2103/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2104/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.364000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2105/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.387000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2106/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.371000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2107/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2108/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2109/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.383000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2110/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.346000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2111/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2112/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.400000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2113/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2114/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2115/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2116/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2117/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2118/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2119/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2120/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2121/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2122/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2123/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2124/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2125/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2126/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2127/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2128/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2129/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2130/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2131/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2132/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2133/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2134/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2135/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2136/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2137/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2138/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2139/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2140/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2141/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2142/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2143/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2144/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2145/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2146/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2147/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2148/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2149/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2150/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2151/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2152/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2153/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2154/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.346000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2155/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.137000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2156/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.304000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2157/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.421000\n",
      "best val_acc of the best model: 0.400000\n",
      "\n",
      "(test 2158/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.421000\n",
      "\n",
      "(test 2159/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.412000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2160/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2161/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2162/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.405000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2163/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.417000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2164/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.425000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2165/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.414000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2166/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2167/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.426000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2168/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2169/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.342000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2170/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.391000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2171/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2172/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2173/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.387000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2174/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.380000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2175/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.396000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2176/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.390000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2177/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2178/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.348000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2179/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2180/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2181/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2182/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2183/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2184/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2185/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2186/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2187/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2188/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2189/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2190/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2191/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2192/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2193/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2194/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2195/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2196/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2197/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2198/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2199/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2200/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2201/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2202/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2203/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2204/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2205/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2206/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2207/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2208/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2209/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2210/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2211/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2212/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.350000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2213/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.353000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2214/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2215/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2216/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2217/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.317000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2218/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2219/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.354000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2220/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2221/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2222/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.369000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2223/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.417000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2224/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2225/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2226/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.436000\n",
      "\n",
      "(test 2227/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.437000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2228/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2229/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.437000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2230/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.423000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2231/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2232/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.444000\n",
      "\n",
      "(test 2233/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2234/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2235/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.400000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2236/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.398000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2237/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.407000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2238/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.408000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2239/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.406000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2240/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.399000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2241/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.422000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2242/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.400000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2243/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.406000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2244/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.383000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2245/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2246/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2247/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2248/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.082000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2249/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2250/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2251/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2252/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2253/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2254/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2255/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2256/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2257/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2258/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2259/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2260/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2261/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2262/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2263/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2264/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2265/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2266/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2267/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2268/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2269/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2270/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2271/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2272/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2273/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2274/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2275/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2276/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2277/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2278/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.370000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2279/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2280/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.341000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2281/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2282/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.382000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2283/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.350000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2284/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.383000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2285/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2286/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2287/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.398000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2288/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2289/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2290/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2291/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2292/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.440000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2293/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2294/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2295/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.450000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2296/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2297/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.454000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2298/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2299/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2300/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2301/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.416000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2302/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.420000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2303/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.418000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2304/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.424000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2305/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.424000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2306/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2307/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.419000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2308/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.418000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2309/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2310/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2311/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2312/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2313/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2314/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2315/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2316/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2317/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2318/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.078000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2319/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2320/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.079000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2321/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2322/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2323/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2324/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2325/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2326/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2327/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2328/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2329/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2330/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2331/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2332/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2333/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2334/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2335/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.256000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2336/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2337/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2338/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2339/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2340/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2341/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2342/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2343/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2344/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.358000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2345/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.367000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2346/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.360000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2347/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2348/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.373000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2349/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2350/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2351/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2352/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2353/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.335000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2354/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2355/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.440000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2356/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2357/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2358/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.417000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2359/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2360/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2361/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2362/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2363/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.418000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2364/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2365/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2366/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2367/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2368/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.431000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2369/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.423000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2370/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2371/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.437000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2372/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.450000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2373/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2374/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.419000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2375/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.421000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2376/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2377/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2378/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2379/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2380/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2381/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2382/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2383/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2384/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2385/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.181000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2386/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2387/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.183000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2388/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2389/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.252000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2390/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2391/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2392/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2393/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2394/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2395/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2396/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2397/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2398/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2399/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2400/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2401/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2402/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2403/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2404/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2405/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2406/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2407/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2408/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2409/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2410/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2411/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.376000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2412/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.386000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2413/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.366000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2414/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2415/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.381000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2416/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.345000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2417/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.384000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2418/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2419/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.389000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2420/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.373000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2421/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.426000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2422/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2423/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2424/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.423000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2425/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2426/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2427/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2428/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2429/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.442000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2430/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.442000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2431/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.424000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2432/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2433/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.468000\n",
      "best val_acc of the best model: 0.456000\n",
      "\n",
      "(test 2434/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2435/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.422000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2436/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2437/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.446000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2438/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.452000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2439/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.455000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2440/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.420000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2441/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.455000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2442/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2443/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2444/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2445/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2446/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.193000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2447/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2448/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2449/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2450/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2451/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.159000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2452/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2453/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.178000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2454/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2455/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2456/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2457/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2458/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2459/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2460/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2461/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2462/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2463/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2464/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2465/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2466/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2467/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2468/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2469/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2470/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2471/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2472/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2473/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2474/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2475/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2476/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.388000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2477/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2478/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.347000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2479/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.380000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2480/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.380000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2481/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2482/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.379000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2483/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2484/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2485/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.362000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2486/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.351000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2487/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.422000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2488/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.421000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2489/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2490/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.439000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2491/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2492/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2493/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.422000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2494/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.442000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2495/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2496/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2497/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2498/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.420000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2499/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2500/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.438000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2501/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2502/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2503/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2504/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2505/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2506/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.454000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2507/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2508/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2509/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2510/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2511/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.184000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2512/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2513/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2514/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.158000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2515/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2516/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2517/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2518/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2519/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2520/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2521/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2522/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2523/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2524/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2525/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2526/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2527/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2528/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2529/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2530/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2531/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.268000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2532/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2533/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.282000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2534/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2535/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2536/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2537/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.312000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2538/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.275000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2539/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2540/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.286000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2541/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2542/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2543/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.373000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2544/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.393000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2545/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.391000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2546/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2547/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.374000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2548/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2549/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.385000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2550/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2551/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.378000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2552/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.404000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2553/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2554/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2555/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2556/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2557/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2558/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.438000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2559/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.439000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2560/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2561/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.450000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2562/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2563/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2564/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2565/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2566/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2567/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.455000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2568/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.431000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2569/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2570/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.461000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2571/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2572/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.454000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2573/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2574/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2575/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2576/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2577/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.147000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2578/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2579/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2580/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2581/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2582/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2583/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2584/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2585/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2586/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2587/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2588/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2589/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2590/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2591/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2592/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2593/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2594/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2595/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2596/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.146000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2597/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2598/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2599/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2600/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.254000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2601/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2602/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2603/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2604/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.271000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2605/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2606/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2607/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2608/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.408000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2609/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2610/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.365000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2611/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.385000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2612/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.367000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2613/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.386000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2614/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2615/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.348000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2616/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2617/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.339000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2618/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.346000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2619/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.452000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2620/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2621/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2622/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.431000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2623/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.438000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2624/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2625/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.458000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2626/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2627/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2628/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2629/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.424000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2630/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2631/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.439000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2632/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.431000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2633/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2634/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2635/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2636/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2637/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2638/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2639/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.439000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2640/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.500000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2641/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2642/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2643/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2644/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2645/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2646/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2647/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2648/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2649/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2650/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2651/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.090000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2652/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2653/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2654/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2655/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2656/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2657/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2658/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2659/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2660/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2661/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2662/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2663/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2664/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2665/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2666/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2667/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2668/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2669/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2670/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2671/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2672/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2673/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2674/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2675/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2676/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2677/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2678/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2679/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2680/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2681/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2682/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.326000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2683/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2684/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2685/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.471000\n",
      "best val_acc of the best model: 0.468000\n",
      "\n",
      "(test 2686/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.471000\n",
      "\n",
      "(test 2687/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.460000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2688/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.470000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2689/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.464000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2690/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2691/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2692/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2693/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2694/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2695/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2696/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2697/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.471000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2698/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2699/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2700/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.457000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2701/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.464000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2702/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2703/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.468000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2704/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.459000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2705/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.477000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2706/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2707/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2708/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.092000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2709/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2710/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2711/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2712/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2713/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2714/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2715/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2716/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2717/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2718/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2719/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2720/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2721/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2722/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2723/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2724/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2725/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2726/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2727/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2728/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2729/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2730/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2731/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2732/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2733/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2734/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2735/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2736/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2737/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2738/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2739/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2740/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2741/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2742/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2743/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.403000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2744/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.421000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2745/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2746/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.415000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2747/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.131000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2748/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.413000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2749/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2750/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.425000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2751/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2752/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.477000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2753/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2754/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2755/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.496000\n",
      "\n",
      "(test 2756/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2757/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2758/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2759/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2760/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2761/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2762/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2763/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2764/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2765/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.468000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2766/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2767/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2768/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2769/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2770/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.458000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2771/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.461000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2772/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.450000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2773/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2774/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2775/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2776/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2777/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2778/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2779/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2780/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2781/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2782/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2783/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2784/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2785/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2786/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2787/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2788/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2789/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2790/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2791/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2792/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2793/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2794/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2795/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2796/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2797/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2798/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2799/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2800/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2801/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2802/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2803/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2804/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2805/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2806/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.455000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2807/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2808/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.422000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2809/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2810/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.431000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2811/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.415000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2812/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2813/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2814/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.405000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2815/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.408000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2816/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2817/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2818/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2819/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2820/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2821/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2822/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2823/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2824/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2825/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2826/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2827/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2828/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2829/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2830/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.468000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2831/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2832/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.470000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2833/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2834/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.470000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2835/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2836/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2837/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2838/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.479000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2839/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2840/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2841/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2842/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2843/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2844/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2845/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2846/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2847/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2848/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2849/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2850/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2851/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2852/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2853/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.137000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2854/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2855/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2856/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.138000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2857/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2858/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2859/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2860/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2861/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2862/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2863/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2864/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2865/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2866/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2867/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2868/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2869/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2870/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2871/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.300000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2872/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.426000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2873/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.421000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2874/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.410000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2875/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.413000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2876/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.419000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2877/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2878/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.446000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2879/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2880/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2881/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.416000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2882/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.413000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2883/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2884/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2885/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2886/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2887/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2888/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2889/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.479000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2890/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2891/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.501000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2892/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2893/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2894/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2895/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2896/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2897/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2898/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2899/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2900/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2901/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2902/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2903/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2904/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2905/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2906/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2907/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2908/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2909/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2910/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2911/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2912/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2913/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2914/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2915/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2916/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2917/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2918/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2919/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2920/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2921/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2922/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2923/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2924/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2925/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2926/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2927/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2928/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.252000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2929/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2930/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2931/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2932/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2933/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2934/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2935/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2936/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.278000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2937/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2938/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.420000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2939/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2940/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2941/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2942/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2943/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.430000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2944/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2945/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.440000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2946/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.433000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2947/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.454000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2948/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.418000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2949/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2950/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2951/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2952/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2953/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2954/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.503000\n",
      "\n",
      "(test 2955/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2956/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2957/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.467000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2958/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2959/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2960/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2961/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2962/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2963/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2964/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2965/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2966/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2967/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2968/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2969/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2970/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2971/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.175000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2972/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.157000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2973/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.164000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2974/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2975/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2976/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2977/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2978/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.161000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2979/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.165000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2980/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.170000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2981/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.163000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2982/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2983/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2984/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2985/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2986/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2987/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2988/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2989/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.248000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2990/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 2991/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2992/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2993/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2994/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2995/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2996/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2997/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2998/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 2999/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3000/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3001/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.307000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3002/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3003/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3004/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.452000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3005/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.427000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3006/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3007/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3008/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3009/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3010/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.435000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3011/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.440000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3012/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.426000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3013/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3014/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.414000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3015/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3016/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3017/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.499000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3018/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.474000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3019/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3020/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3021/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.491000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3022/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3023/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3024/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3025/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3026/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3027/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3028/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3029/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3030/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3031/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3032/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3033/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3034/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3035/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3036/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3037/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.207000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3038/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3039/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.182000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3040/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3041/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3042/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.165000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3043/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.145000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3044/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3045/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.162000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3046/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.172000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3047/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.180000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3048/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.284000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3049/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.269000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3050/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3051/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3052/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3053/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3054/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.291000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3055/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3056/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3057/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3058/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3059/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.293000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3060/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3061/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.299000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3062/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3063/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3064/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.296000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3065/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3066/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3067/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3068/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3069/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.286000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3070/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3071/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3072/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.457000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3073/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.437000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3074/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3075/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3076/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.443000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3077/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.436000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3078/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3079/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3080/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3081/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3082/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3083/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3084/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3085/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3086/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3087/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3088/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.491000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3089/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3090/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3091/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3092/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3093/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3094/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3095/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3096/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3097/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3098/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.470000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3099/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3100/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3101/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3102/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3103/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3104/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3105/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3106/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3107/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3108/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3109/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3110/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.139000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3111/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3112/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3113/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3114/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.194000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3115/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.167000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3116/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.137000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3117/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3118/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3119/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.177000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3120/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3121/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.191000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3122/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.174000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3123/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3124/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3125/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3126/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.272000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3127/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.284000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3128/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3129/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.307000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3130/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3131/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3132/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3133/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.282000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3134/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3135/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3136/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3137/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3138/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3139/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.437000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3140/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.465000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3141/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.449000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3142/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.457000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3143/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.446000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3144/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.461000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3145/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3146/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.442000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3147/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3148/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3149/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.482000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3150/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3151/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3152/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3153/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3154/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3155/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3156/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3157/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3158/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3159/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3160/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3161/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3162/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3163/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3164/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3165/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.479000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3166/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.499000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3167/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3168/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.600000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3169/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3170/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3171/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3172/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3173/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3174/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3175/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3176/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3177/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3178/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3179/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3180/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3181/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3182/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3183/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3184/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3185/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3186/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3187/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.136000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3188/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3189/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3190/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3191/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3192/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3193/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3194/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3195/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3196/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3197/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3198/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3199/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3200/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3201/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3202/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.444000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3203/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3204/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3205/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3206/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3207/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3208/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3209/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3210/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3211/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3212/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3213/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3214/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.516000\n",
      "\n",
      "(test 3215/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3216/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3217/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3218/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3219/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.507000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3220/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.498000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3221/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3222/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3223/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3224/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.499000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3225/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.507000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3226/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3227/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3228/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.501000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3229/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3230/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.507000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3231/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3232/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3233/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3234/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3235/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3236/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.140000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3237/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3238/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3239/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3240/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3241/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.092000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3242/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3243/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3244/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3245/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3246/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3247/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3248/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3249/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3250/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3251/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3252/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3253/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3254/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3255/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3256/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3257/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3258/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3259/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3260/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3261/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3262/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3263/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3264/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3265/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.083000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3266/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3267/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3268/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.461000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3269/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.464000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3270/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3271/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3272/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3273/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3274/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.458000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3275/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.428000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3276/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3277/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3278/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.446000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3279/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3280/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3281/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3282/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3283/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3284/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3285/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3286/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3287/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3288/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3289/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3290/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3291/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3292/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3293/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3294/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3295/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3296/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3297/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3298/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3299/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3300/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3301/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3302/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3303/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3304/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.079000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3305/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3306/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3307/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3308/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3309/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3310/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3311/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3312/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3313/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3314/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3315/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3316/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3317/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3318/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3319/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3320/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3321/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3322/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3323/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.086000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3324/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3325/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3326/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3327/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3328/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3329/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3330/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3331/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3332/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3333/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3334/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.472000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3335/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3336/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3337/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3338/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3339/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.459000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3340/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.477000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3341/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3342/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3343/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.460000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3344/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.465000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3345/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3346/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3347/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3348/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3349/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.522000\n",
      "\n",
      "(test 3350/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.510000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3351/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3352/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3353/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3354/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3355/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3356/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3357/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3358/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3359/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.507000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3360/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3361/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3362/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3363/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3364/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3365/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3366/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3367/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3368/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3369/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3370/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.090000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3371/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.088000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3372/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.079000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3373/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3374/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3375/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3376/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3377/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3378/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3379/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3380/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3381/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.250000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3382/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3383/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3384/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3385/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3386/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.208000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3387/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3388/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3389/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3390/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3391/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3392/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.294000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3393/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3394/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3395/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.265000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3396/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.250000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3397/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3398/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3399/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3400/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.486000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3401/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3402/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3403/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3404/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3405/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3406/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3407/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.457000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3408/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.468000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3409/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.467000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3410/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.471000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3411/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3412/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.523000\n",
      "\n",
      "(test 3413/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3414/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3415/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3416/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.510000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3417/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3418/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3419/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.510000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3420/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3421/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3422/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3423/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3424/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3425/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3426/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3427/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3428/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3429/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3430/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3431/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3432/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3433/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3434/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3435/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3436/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3437/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3438/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3439/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3440/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3441/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3442/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3443/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3444/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3445/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3446/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3447/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3448/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3449/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3450/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3451/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.256000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3452/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.196000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3453/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3454/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3455/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3456/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3457/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3458/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3459/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3460/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3461/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3462/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.242000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3463/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3464/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3465/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3466/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3467/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3468/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.484000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3469/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.461000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3470/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.469000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3471/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3472/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3473/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3474/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.456000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3475/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3476/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.464000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3477/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3478/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3479/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3480/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3481/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3482/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3483/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3484/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3485/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3486/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3487/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3488/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3489/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3490/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3491/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3492/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3493/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3494/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3495/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3496/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3497/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3498/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3499/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.187000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3500/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.179000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3501/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3502/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3503/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.166000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3504/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3505/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3506/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3507/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3508/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.192000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3509/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3510/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.269000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3511/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3512/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.249000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3513/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3514/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3515/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3516/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3517/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3518/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3519/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3520/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3521/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3522/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3523/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3524/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.318000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3525/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3526/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3527/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3528/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3529/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3530/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3531/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3532/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.470000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3533/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.463000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3534/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.471000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3535/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.452000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3536/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.464000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3537/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3538/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3539/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3540/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.469000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3541/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3542/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3543/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3544/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.526000\n",
      "\n",
      "(test 3545/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3546/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3547/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3548/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3549/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3550/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3551/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3552/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3553/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3554/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3555/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3556/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3557/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3558/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3559/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3560/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3561/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3562/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3563/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3564/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3565/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.211000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3566/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3567/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3568/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3569/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3570/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3571/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3572/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3573/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3574/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.195000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3575/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3576/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.300000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3577/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3578/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3579/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.284000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3580/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.298000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3581/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.282000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3582/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.285000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3583/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.262000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3584/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3585/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3586/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.302000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3587/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.336000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3588/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3589/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.306000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3590/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.343000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3591/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.391000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3592/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.298000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3593/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3594/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.317000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3595/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3596/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.359000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3597/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.341000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3598/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.465000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3599/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3600/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3601/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3602/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.473000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3603/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3604/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.475000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3605/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.460000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3606/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.463000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3607/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3608/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3609/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3610/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3611/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3612/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3613/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3614/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3615/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3616/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3617/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3618/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3619/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3620/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3621/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3622/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3623/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3624/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3625/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3626/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3627/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3628/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3629/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3630/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3631/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3632/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3633/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3634/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3635/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3636/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3637/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3638/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3639/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3640/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3641/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3642/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.169000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3643/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.226000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3644/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.225000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3645/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.262000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3646/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3647/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3648/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.205000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3649/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.186000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3650/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.190000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3651/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3652/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.206000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3653/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.318000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3654/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3655/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.333000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3656/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.333000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3657/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.322000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3658/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.314000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3659/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3660/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3661/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3662/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.365000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3663/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.363000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3664/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.496000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3665/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3666/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.499000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3667/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3668/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3669/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3670/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3671/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.498000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3672/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.498000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3673/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.487000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3674/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.483000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3675/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3676/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.531000\n",
      "\n",
      "(test 3677/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3678/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3679/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3680/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3681/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3682/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3683/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3684/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3685/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3686/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.506000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3687/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.507000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3688/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3689/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3690/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3691/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3692/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3693/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3694/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3695/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3696/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.700000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3697/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3698/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3699/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3700/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3701/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3702/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3703/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3704/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3705/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3706/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3707/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3708/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3709/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3710/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3711/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3712/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3713/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3714/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.077000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3715/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3716/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3717/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3718/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3719/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3720/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3721/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3722/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3723/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3724/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3725/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3726/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3727/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3728/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3729/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3730/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3731/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3732/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3733/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3734/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3735/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3736/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3737/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3738/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3739/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3740/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3741/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3742/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3743/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3744/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3745/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.535000\n",
      "\n",
      "(test 3746/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.538000\n",
      "\n",
      "(test 3747/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3748/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3749/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3750/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3751/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3752/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3753/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3754/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3755/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3756/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3757/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3758/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3759/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3760/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3761/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3762/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3763/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3764/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3765/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3766/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3767/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3768/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3769/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.089000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3770/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3771/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3772/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.078000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3773/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3774/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3775/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3776/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3777/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3778/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3779/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3780/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3781/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3782/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3783/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.092000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3784/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3785/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3786/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.095000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3787/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3788/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3789/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3790/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3791/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3792/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3793/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3794/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3795/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3796/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3797/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3798/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.481000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3799/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.501000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3800/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3801/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3802/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3803/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3804/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3805/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3806/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.493000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3807/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3808/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3809/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.543000\n",
      "\n",
      "(test 3810/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3811/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3812/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3813/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3814/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3815/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3816/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3817/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3818/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3819/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3820/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3821/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3822/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3823/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3824/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3825/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3826/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.513000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3827/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3828/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3829/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3830/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3831/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3832/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3833/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.128000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3834/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3835/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3836/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3837/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3838/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3839/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3840/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3841/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3842/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3843/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3844/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3845/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3846/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3847/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3848/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3849/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3850/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3851/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.216000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3852/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.269000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3853/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3854/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3855/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3856/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.132000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3857/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3858/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3859/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.098000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3860/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3861/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3862/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3863/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3864/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3865/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3866/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3867/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.480000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3868/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3869/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3870/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3871/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.490000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3872/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3873/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3874/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3875/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3876/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3877/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3878/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3879/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3880/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3881/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3882/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3883/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3884/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3885/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3886/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3887/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3888/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3889/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3890/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3891/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3892/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3893/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3894/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3895/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3896/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3897/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3898/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3899/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3900/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3901/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3902/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3903/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3904/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3905/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3906/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3907/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.087000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3908/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3909/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3910/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3911/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3912/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3913/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.210000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3914/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3915/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3916/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3917/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3918/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3919/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3920/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3921/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.306000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3922/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.213000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3923/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.228000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3924/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3925/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3926/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3927/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3928/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3929/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3930/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3931/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.495000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3932/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.488000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3933/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.503000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3934/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3935/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3936/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3937/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3938/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3939/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3940/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3941/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3942/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3943/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3944/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3945/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3946/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3947/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3948/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3949/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3950/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3951/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3952/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3953/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3954/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3955/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3956/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3957/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3958/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3959/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3960/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3961/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3962/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3963/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3964/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3965/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3966/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3967/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3968/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3969/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3970/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3971/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3972/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3973/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.212000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3974/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3975/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3976/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.259000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 3977/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3978/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.263000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3979/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3980/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3981/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.249000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3982/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.230000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3983/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.284000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3984/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3985/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3986/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3987/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3988/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3989/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3990/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3991/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.221000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3992/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3993/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3994/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3995/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3996/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3997/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3998/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.497000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 3999/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.504000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4000/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4001/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4002/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4003/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.499000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4004/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4005/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4006/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4007/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4008/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4009/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4010/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4011/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4012/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4013/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4014/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4015/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4016/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4017/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4018/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4019/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4020/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4021/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4022/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4023/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4024/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4025/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4026/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4027/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.209000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4028/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4029/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4030/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4031/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4032/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4033/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4034/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4035/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4036/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4037/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.218000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4038/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4039/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4040/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.280000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4041/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4042/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4043/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4044/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.248000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4045/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4046/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4047/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4048/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4049/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.324000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4050/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4051/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.269000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4052/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4053/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.242000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4054/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.330000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4055/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.249000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4056/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4057/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4058/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4059/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4060/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4061/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4062/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.500000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4063/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4064/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.509000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4065/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4066/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.494000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4067/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4068/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4069/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.489000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4070/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.492000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4071/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4072/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4073/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4074/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4075/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4076/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4077/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4078/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4079/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.547000\n",
      "\n",
      "(test 4080/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.548000\n",
      "\n",
      "(test 4081/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4082/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4083/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4084/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4085/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4086/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4087/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4088/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4089/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.516000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4090/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4091/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4092/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4093/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4094/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4095/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.274000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4096/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4097/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4098/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.254000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4099/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4100/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4101/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4102/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4103/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4104/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4105/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4106/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.344000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4107/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.337000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4108/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4109/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.356000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4110/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.323000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4111/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.355000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4112/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4113/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.279000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4114/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.287000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4115/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.368000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4116/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.397000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4117/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.409000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4118/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.361000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4119/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.402000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4120/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.394000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4121/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.415000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4122/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.357000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4123/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.405000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4124/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.377000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4125/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.407000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4126/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4127/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4128/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4129/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4130/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4131/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4132/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4133/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4134/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.511000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4135/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.505000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4136/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.514000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4137/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4138/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4139/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4140/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4141/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4142/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4143/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4144/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4145/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4146/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4147/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4148/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4149/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4150/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4151/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4152/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.510000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4153/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4154/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4155/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4156/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4157/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4158/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4159/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4160/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4161/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4162/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.141000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4163/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4164/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4165/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4166/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.129000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4167/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4168/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4169/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4170/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4171/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.248000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4172/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4173/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.262000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4174/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.242000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4175/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4176/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4177/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4178/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.264000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4179/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4180/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.266000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4181/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.404000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4182/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.402000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4183/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.402000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4184/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.398000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4185/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.425000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4186/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.401000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4187/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.399000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4188/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.382000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4189/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.419000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4190/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.426000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4191/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.369000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4192/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.517000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4193/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4194/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4195/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4196/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4197/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4198/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4199/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4200/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.502000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4201/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4202/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.519000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4203/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4204/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4205/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4206/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4207/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4208/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4209/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4210/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4211/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4212/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4213/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4214/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4215/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4216/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4217/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4218/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4219/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4220/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4221/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4222/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4223/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4224/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4225/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4226/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4227/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4228/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4229/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4230/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4231/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4232/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4233/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.094000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4234/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4235/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4236/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4237/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4238/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4239/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4240/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4241/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4242/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4243/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4244/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4245/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4246/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4247/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4248/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4249/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4250/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4251/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4252/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4253/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4254/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4255/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.118000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4256/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4257/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.137000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4258/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4259/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4260/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4261/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4262/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4263/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4264/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4265/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4266/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4267/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4268/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4269/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.554000\n",
      "\n",
      "(test 4270/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4271/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4272/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4273/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4274/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4275/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4276/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4277/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4278/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4279/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4280/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.440000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4281/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.425000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4282/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4283/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.515000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4284/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4285/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4286/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4287/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.091000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4288/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.384000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4289/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.485000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4290/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-09 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4291/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4292/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4293/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4294/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4295/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4296/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4297/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4298/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4299/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4300/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4301/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4302/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4303/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4304/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4305/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4306/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4307/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4308/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4309/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4310/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4311/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4312/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4313/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4314/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4315/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4316/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4317/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4318/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4319/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4320/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4321/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4322/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.105000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4323/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4324/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4325/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4326/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4327/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4328/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4329/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4330/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4331/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.097000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4332/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4333/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.099000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4334/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4335/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4336/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4337/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4338/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.557000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4339/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4340/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4341/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4342/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4343/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4344/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4345/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4346/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4347/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4348/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4349/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4350/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4351/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4352/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4353/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4354/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4355/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4356/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-08 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4357/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4358/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.108000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4359/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4360/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4361/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4362/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4363/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4364/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.127000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4365/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4366/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4367/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4368/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4369/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4370/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4371/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4372/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4373/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4374/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4375/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4376/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.085000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4377/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4378/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.093000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4379/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.110000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4380/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4381/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4382/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4383/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.109000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4384/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4385/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.115000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4386/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4387/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4388/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.126000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4389/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4390/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4391/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4392/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4393/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4394/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.125000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4395/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4396/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.522000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4397/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.117000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4398/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4399/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4400/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4401/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4402/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4403/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4404/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4405/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4406/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4407/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4408/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4409/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4410/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4411/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4412/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4413/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4414/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4415/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4416/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4417/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4418/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.558000\n",
      "\n",
      "(test 4419/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4420/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4421/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4422/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-07 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4423/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4424/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.100000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4425/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.102000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4426/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.111000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4427/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4428/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4429/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4430/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.116000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4431/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.101000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4432/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.123000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4433/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.106000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4434/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4435/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.124000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4436/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.257000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4437/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4438/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.119000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4439/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.079000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4440/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.197000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4441/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.107000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4442/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.096000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4443/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4444/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.084000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4445/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.258000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4446/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.113000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4447/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4448/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4449/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4450/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.268000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4451/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4452/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.114000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4453/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.104000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4454/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.292000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4455/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.112000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4456/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4457/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4458/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.508000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4459/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4460/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4461/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4462/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.512000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4463/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4464/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.526000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4465/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4466/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.518000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4467/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4468/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4469/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4470/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4471/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4472/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4473/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4474/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4475/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.561000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4476/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4477/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4478/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4479/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4480/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4481/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4482/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4483/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4484/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4485/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4486/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4487/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4488/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-06 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4489/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4490/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.199000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4491/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4492/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.204000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4493/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4494/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.201000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4495/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4496/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.203000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4497/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.200000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4498/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.202000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4499/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.198000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4500/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.242000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4501/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.256000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4502/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4503/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4504/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4505/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.229000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4506/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4507/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4508/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4509/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.214000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4510/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.231000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4511/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4512/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.246000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4513/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.238000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4514/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.223000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4515/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.224000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4516/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.248000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4517/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.240000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4518/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4519/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.247000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4520/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4521/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.250000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4522/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.525000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4523/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4524/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4525/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4526/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4527/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4528/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4529/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4530/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4531/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.528000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4532/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4533/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4534/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4535/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4536/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4537/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4538/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4539/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4540/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4541/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4542/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4543/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4544/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4545/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4546/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4547/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4548/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4549/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4550/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4551/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4552/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4553/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4554/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-05 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4555/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.215000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4556/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.220000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4557/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4558/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.233000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4559/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.232000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4560/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.222000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4561/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.219000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4562/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4563/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.189000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4564/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.237000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4565/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.234000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4566/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4567/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.252000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4568/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.239000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4569/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.217000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4570/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4571/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4572/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4573/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.235000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4574/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.243000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4575/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.245000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4576/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.268000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4577/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.301000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4578/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.328000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4579/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.244000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4580/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.340000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4581/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.316000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4582/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.251000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4583/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.241000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4584/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.261000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4585/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.236000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4586/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.253000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4587/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.227000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4588/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.535000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4589/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.521000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4590/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4591/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4592/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.523000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4593/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4594/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4595/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4596/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4597/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4598/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.520000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4599/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4600/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4601/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4602/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4603/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4604/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.529000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4605/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4606/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4607/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4608/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4609/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4610/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4611/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4612/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4613/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4614/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4615/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4616/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4617/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4618/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.533000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4619/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4620/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-04 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4621/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.281000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4622/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.267000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4623/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.303000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4624/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.282000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4625/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.283000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4626/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.288000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4627/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.310000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4628/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.273000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4629/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.290000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4630/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.255000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4631/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.277000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4632/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4633/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.397000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4634/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.338000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4635/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.415000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4636/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.357000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4637/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.400000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4638/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.402000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4639/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.406000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4640/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.385000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4641/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.375000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4642/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.335000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4643/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.459000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4644/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.463000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4645/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4646/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.478000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4647/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.466000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4648/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.452000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4649/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.471000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4650/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.454000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4651/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.476000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4652/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4653/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.465000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4654/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4655/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4656/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4657/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4658/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4659/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.565000\n",
      "best val_acc of the best model: 0.563000\n",
      "\n",
      "(test 4660/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.532000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4661/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.546000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4662/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4663/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4664/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.527000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4665/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4666/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4667/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4668/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4669/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4670/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4671/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4672/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.544000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4673/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4674/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4675/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4676/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4677/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4678/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4679/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4680/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4681/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4682/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.524000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4683/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4684/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.537000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4685/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4686/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-03 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4687/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-06\n",
      "best val_acc of model: 0.103000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4688/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-05\n",
      "best val_acc of model: 0.130000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4689/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-04\n",
      "best val_acc of model: 0.121000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4690/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-03\n",
      "best val_acc of model: 0.120000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4691/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-02\n",
      "best val_acc of model: 0.135000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4692/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e-01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4693/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 1.000000e+01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4694/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 3.000000e+01\n",
      "best val_acc of model: 0.134000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4695/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 5.000000e+01\n",
      "best val_acc of model: 0.133000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4696/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 7.000000e+01\n",
      "best val_acc of model: 0.143000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4697/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-07 reg: 9.000000e+01\n",
      "best val_acc of model: 0.122000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4698/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-06\n",
      "best val_acc of model: 0.305000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4699/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-05\n",
      "best val_acc of model: 0.289000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4700/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-04\n",
      "best val_acc of model: 0.286000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4701/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-03\n",
      "best val_acc of model: 0.295000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4702/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-02\n",
      "best val_acc of model: 0.297000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4703/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e-01\n",
      "best val_acc of model: 0.254000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4704/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 1.000000e+01\n",
      "best val_acc of model: 0.250000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4705/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 3.000000e+01\n",
      "best val_acc of model: 0.276000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4706/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 5.000000e+01\n",
      "best val_acc of model: 0.298000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4707/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 7.000000e+01\n",
      "best val_acc of model: 0.270000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4708/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-06 reg: 9.000000e+01\n",
      "best val_acc of model: 0.268000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4709/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-06\n",
      "best val_acc of model: 0.442000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4710/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-05\n",
      "best val_acc of model: 0.462000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4711/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-04\n",
      "best val_acc of model: 0.432000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4712/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-03\n",
      "best val_acc of model: 0.441000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4713/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-02\n",
      "best val_acc of model: 0.447000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4714/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e-01\n",
      "best val_acc of model: 0.434000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4715/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 1.000000e+01\n",
      "best val_acc of model: 0.445000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4716/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 3.000000e+01\n",
      "best val_acc of model: 0.429000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4717/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 5.000000e+01\n",
      "best val_acc of model: 0.451000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4718/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 7.000000e+01\n",
      "best val_acc of model: 0.448000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4719/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-05 reg: 9.000000e+01\n",
      "best val_acc of model: 0.453000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4720/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-06\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4721/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-05\n",
      "best val_acc of model: 0.530000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4722/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-04\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4723/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-03\n",
      "best val_acc of model: 0.557000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4724/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-02\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4725/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e-01\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4726/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 1.000000e+01\n",
      "best val_acc of model: 0.531000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4727/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 3.000000e+01\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4728/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 5.000000e+01\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4729/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 7.000000e+01\n",
      "best val_acc of model: 0.540000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4730/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-04 reg: 9.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 4731/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.570000\n",
      "best val_acc of the best model: 0.565000\n",
      "\n",
      "(test 4732/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.541000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4733/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-04\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4734/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-03\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4735/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-02\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4736/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-01\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4737/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4738/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 3.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4739/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4740/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 7.000000e+01\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4741/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 9.000000e+01\n",
      "best val_acc of model: 0.557000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4742/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-06\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4743/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-05\n",
      "best val_acc of model: 0.539000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4744/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-04\n",
      "best val_acc of model: 0.534000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4745/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-03\n",
      "best val_acc of model: 0.548000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4746/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-02\n",
      "best val_acc of model: 0.542000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4747/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e-01\n",
      "best val_acc of model: 0.543000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4748/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 1.000000e+01\n",
      "best val_acc of model: 0.536000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4749/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 3.000000e+01\n",
      "best val_acc of model: 0.538000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4750/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 5.000000e+01\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4751/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 7.000000e+01\n",
      "best val_acc of model: 0.550000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 4752/4752) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-02 reg: 9.000000e+01\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters tunning 1: coarse searching\n",
    "\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# find batch/layer normalization and dropout useful. Store your best model in  #\n",
    "# the best_model variable.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "num_hidden = np.arange(5,10,5)  # fixed at 5 layers\n",
    "dropout = np.arange(0.1, 1, 0.1) \n",
    "normalization = ['batchnorm']  # fixed at batchnorm\n",
    "weight_scale = 1/10**np.arange(9,1,-1)\n",
    "learning_rate = 1/10**np.arange(7,1,-1)\n",
    "regularization = np.append(1/10**np.arange(6,0,-1), np.arange(10,100,20))\n",
    "print('parameters tunning:')\n",
    "print('num_hidden: ' , num_hidden)\n",
    "print('weight_scale: ', weight_scale)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('regularization: ', regularization)\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "best_params = {}\n",
    "total_tests = len(num_hidden) * len(dropout) * len(normalization) * len(\n",
    "    weight_scale) * len(learning_rate) * len(regularization)\n",
    "test_count = 0\n",
    "\n",
    "for i in num_hidden:\n",
    "    hidden_dims = list(np.repeat(100, i))\n",
    "    for i_drop in dropout:\n",
    "        for i_scale in weight_scale:\n",
    "            for i_lr in learning_rate:\n",
    "                for i_reg in regularization:\n",
    "                    for i_norm in normalization:\n",
    "                        model = FullyConnectedNet(hidden_dims, dropout=i_drop, normalization=i_norm, \n",
    "                          weight_scale=i_scale, dtype=np.float64)\n",
    "                        solver = Solver(model, data, print_every=1000, num_epochs=10, batch_size=200,\n",
    "                                        update_rule='adam', optim_config={'learning_rate': i_lr}, verbose=False)\n",
    "                        solver.train()\n",
    "                        \n",
    "                        model_best_val_acc = solver.best_val_acc\n",
    "                        test_count += 1\n",
    "                        print('(test %d/%d) ------------------------------------' % (test_count, total_tests))\n",
    "                        print('layer dimension: ', hidden_dims)\n",
    "                        print('normalization: ', i_norm)\n",
    "                        print('dropout: %f weight_init_scale: %e lr: %e reg: %e' % (i_drop, i_scale, i_lr, i_reg))\n",
    "                        print('best val_acc of model: %f' % model_best_val_acc)\n",
    "                        print('best val_acc of the best model: %f' % best_val_acc)\n",
    "                        print()\n",
    "                        if model_best_val_acc > best_val_acc:\n",
    "                            best_val_acc = model_best_val_acc\n",
    "                            best_setting = (hidden_dims.copy(), i_drop, i_scale, i_lr, i_reg, i_norm)\n",
    "                            best_params = solver.best_params\n",
    "                            best_bn_param = model.bn_params\n",
    "                            \n",
    "# save best model\n",
    "hidden_dims, drop, scale, lr, reg, norm = best_setting\n",
    "best_model = FullyConnectedNet(hidden_dims, dropout=drop, normalization=norm, \n",
    "                          weight_scale=scale, dtype=np.float64)\n",
    "best_model.params = best_params\n",
    "best_model.bn_params = best_bn_param\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your model!\n",
    "Run your best model on the validation and test sets. You should achieve above 50% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_dims, drop_out, w_init_scale, lr, reg, norm_scheme\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([100, 100, 100, 100, 100], 0.9, 0.01, 0.001, 1e-06, 'batchnorm')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('hidden_dims, drop_out, w_init_scale, lr, reg, norm_scheme')\n",
    "best_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters tunning:\n",
      "num_hidden:  [5]\n",
      "weight_scale:  [0.01]\n",
      "learning_rate:  [0.001]\n",
      "regularization:  [1e-07, 5e-07, 1e-06, 5e-06, 1e-05, 5e-05]\n",
      "(test 1/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.569000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 2/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.566000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 3/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 4/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 5/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 6/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.800000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 7/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 8/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 9/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 10/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 11/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.567000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 12/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.810000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 13/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.569000\n",
      "\n",
      "(test 14/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.570000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 15/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.567000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 16/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 17/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.549000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 18/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.820000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 19/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 20/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 21/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 22/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 23/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 24/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.830000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.547000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 25/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 26/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 27/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.553000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 28/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 29/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 30/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.840000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 31/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.564000\n",
      "best val_acc of the best model: 0.570000\n",
      "\n",
      "(test 32/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.573000\n",
      "\n",
      "(test 33/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.576000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 34/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 35/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 36/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.850000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 37/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.565000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 38/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 39/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 40/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 41/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 42/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.860000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.576000\n",
      "\n",
      "(test 43/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.580000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 44/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.579000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 45/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.569000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 46/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.570000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 47/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 48/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.870000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 49/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 50/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 51/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.574000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 52/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.545000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 53/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 54/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.880000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 55/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.567000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 56/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.557000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 57/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.580000\n",
      "\n",
      "(test 58/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.582000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 59/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.561000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 60/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.890000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.557000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 61/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.580000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 62/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 63/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.567000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 64/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 65/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.576000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 66/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.900000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 67/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 68/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.554000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 69/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 70/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 71/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.556000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 72/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.910000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 73/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 74/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 75/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 76/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 77/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 78/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.920000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 79/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.564000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 80/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 81/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 82/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 83/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.572000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 84/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.930000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.581000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 85/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 86/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.574000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 87/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.564000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 88/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 89/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.568000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 90/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.940000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.567000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 91/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.574000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 92/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 93/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 94/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.560000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 95/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.573000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 96/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.950000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 97/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.552000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 98/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 99/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 100/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.574000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 101/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.564000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 102/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.960000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.571000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 103/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.563000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 104/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.575000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 105/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.572000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 106/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 107/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.569000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 108/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.970000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.577000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 109/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.561000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 110/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 111/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.559000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 112/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.570000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 113/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.569000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 114/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.980000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.562000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 115/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-07\n",
      "best val_acc of model: 0.555000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 116/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-07\n",
      "best val_acc of model: 0.569000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 117/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-06\n",
      "best val_acc of model: 0.558000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 118/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-06\n",
      "best val_acc of model: 0.551000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n",
      "(test 119/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 1.000000e-05\n",
      "best val_acc of model: 0.570000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test 120/120) ------------------------------------\n",
      "layer dimension:  [100, 100, 100, 100, 100]\n",
      "normalization:  batchnorm\n",
      "dropout: 0.990000 weight_init_scale: 1.000000e-02 lr: 1.000000e-03 reg: 5.000000e-05\n",
      "best val_acc of model: 0.572000\n",
      "best val_acc of the best model: 0.582000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters tunning 2: fine searching\n",
    "\n",
    "################################################################################\n",
    "# TODO: Train the best FullyConnectedNet that you can on CIFAR-10. You might   #\n",
    "# find batch/layer normalization and dropout useful. Store your best model in  #\n",
    "# the best_model variable.                                                     #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "num_hidden = np.arange(5,10,5)  # fixed at 5 layers\n",
    "dropout = np.arange(0.8, 1, 0.01) \n",
    "normalization = ['batchnorm']  # fixed at batchnorm\n",
    "weight_scale = [0.01]  # fixed at 0.01\n",
    "learning_rate = [0.001]  # fixed at 0.001\n",
    "regularization = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "print('parameters tunning:')\n",
    "print('num_hidden: ' , num_hidden)\n",
    "print('weight_scale: ', weight_scale)\n",
    "print('learning_rate: ', learning_rate)\n",
    "print('regularization: ', regularization)\n",
    "\n",
    "\n",
    "best_val_acc = 0\n",
    "best_params = {}\n",
    "total_tests = len(num_hidden) * len(dropout) * len(normalization) * len(\n",
    "    weight_scale) * len(learning_rate) * len(regularization)\n",
    "test_count = 0\n",
    "\n",
    "for i in num_hidden:\n",
    "    hidden_dims = list(np.repeat(100, i))\n",
    "    for i_drop in dropout:\n",
    "        for i_scale in weight_scale:\n",
    "            for i_lr in learning_rate:\n",
    "                for i_reg in regularization:\n",
    "                    for i_norm in normalization:\n",
    "                        model = FullyConnectedNet(hidden_dims, dropout=i_drop, normalization=i_norm, \n",
    "                          weight_scale=i_scale, dtype=np.float64)\n",
    "                        solver = Solver(model, data, print_every=1000, num_epochs=20, batch_size=200,\n",
    "                                        update_rule='adam', optim_config={'learning_rate': i_lr}, verbose=False)\n",
    "                        solver.train()\n",
    "                        \n",
    "                        model_best_val_acc = solver.best_val_acc\n",
    "                        test_count += 1\n",
    "                     \n",
    "                        if model_best_val_acc > best_val_acc:\n",
    "                            best_val_acc = model_best_val_acc\n",
    "                            best_setting = (hidden_dims.copy(), i_drop, i_scale, i_lr, i_reg, i_norm)\n",
    "                            best_params = solver.best_params\n",
    "                            best_bn_param = model.bn_params\n",
    "                            \n",
    "                        print('(test %d/%d) ------------------------------------' % (test_count, total_tests))\n",
    "                        print('layer dimension: ', hidden_dims)\n",
    "                        print('normalization: ', i_norm)\n",
    "                        print('dropout: %f weight_init_scale: %e lr: %e reg: %e' % (i_drop, i_scale, i_lr, i_reg))\n",
    "                        print('best val_acc of model: %f' % model_best_val_acc)\n",
    "                        print('best val_acc of the best model: %f' % best_val_acc)\n",
    "                        print()\n",
    "                            \n",
    "# save best model\n",
    "hidden_dims, drop, scale, lr, reg, norm = best_setting\n",
    "best_model = FullyConnectedNet(hidden_dims, dropout=drop, normalization=norm, \n",
    "                          weight_scale=scale, dtype=np.float64)\n",
    "best_model.params = best_params\n",
    "best_model.bn_params = best_bn_param\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set accuracy:  0.561\n",
      "Test set accuracy:  0.524\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(best_model.loss(data['X_test']), axis=1)\n",
    "y_val_pred = np.argmax(best_model.loss(data['X_val']), axis=1)\n",
    "print('Validation set accuracy: ', (y_val_pred == data['y_val']).mean())\n",
    "print('Test set accuracy: ', (y_test_pred == data['y_test']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
